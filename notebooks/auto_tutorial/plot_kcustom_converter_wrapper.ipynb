{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Implement a new converter using other converters\n\n.. index:: custom converter\n\nIn many cases, a custom models leverages existing models\nwhich already have an associated converter. To convert this\npatchwork, existing converters must be called. This example\nshows how to do that. Example `l-plot-custom-converter`\ncan be rewritten by using a `PCA <https://scikit-learn.org/\nstable/modules/generated/sklearn.decomposition.PCA.html>`_.\nWe could then reuse the converter associated to this model.\n\n## Custom model\n\nLet's implement a simple custom model using\n:epkg:`scikit-learn` API. The model is preprocessing\nwhich decorrelates correlated random variables.\nIf *X* is a matrix of features, $V=\frac{1}{n}X'X$\nis the covariance matrix. We compute $X V^{1/2}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mlprodict.onnxrt import OnnxInference\nfrom pyquickhelper.helpgen.graphviz_helper import plot_graphviz\nimport pickle\nfrom io import BytesIO\nimport numpy\nfrom numpy.testing import assert_almost_equal\nfrom onnxruntime import InferenceSession\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\nfrom skl2onnx import update_registered_converter\nfrom skl2onnx.algebra.onnx_operator import OnnxSubEstimator\nfrom skl2onnx import to_onnx\n\n\nclass DecorrelateTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"\n    Decorrelates correlated gaussian features.\n\n    :param alpha: avoids non inversible matrices\n        by adding *alpha* identity matrix\n\n    *Attributes*\n\n    * `self.mean_`: average\n    * `self.coef_`: square root of the coveriance matrix\n    \"\"\"\n\n    def __init__(self, alpha=0.):\n        BaseEstimator.__init__(self)\n        TransformerMixin.__init__(self)\n        self.alpha = alpha\n\n    def fit(self, X, y=None, sample_weights=None):\n        self.pca_ = PCA(X.shape[1])\n        self.pca_.fit(X)\n        return self\n\n    def transform(self, X):\n        return self.pca_.transform(X)\n\n\ndef test_decorrelate_transformer():\n    data = load_iris()\n    X = data.data\n\n    dec = DecorrelateTransformer()\n    dec.fit(X)\n    pred = dec.transform(X)\n    cov = pred.T @ pred\n    for i in range(cov.shape[0]):\n        cov[i, i] = 1.\n    assert_almost_equal(numpy.identity(4), cov)\n\n    st = BytesIO()\n    pickle.dump(dec, st)\n    dec2 = pickle.load(BytesIO(st.getvalue()))\n    assert_almost_equal(dec.transform(X), dec2.transform(X))\n\n\ntest_decorrelate_transformer()\n\ndata = load_iris()\nX = data.data\n\ndec = DecorrelateTransformer()\ndec.fit(X)\npred = dec.transform(X[:5])\nprint(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion into ONNX\n\nLet's try to convert it and see what happens.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    to_onnx(dec, X.astype(numpy.float32))\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This error means there is no converter associated\nto *DecorrelateTransformer*. Let's do it.\nIt requires to implement the two following\nfunctions, a shape calculator and a converter\nwith the same signature as below.\nFirst the shape calculator. We retrieve the input type\nadd tells the output type has the same type,\nthe same number of rows and a specific number of columns.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def decorrelate_transformer_shape_calculator(operator):\n    op = operator.raw_operator\n    input_type = operator.inputs[0].type.__class__\n    input_dim = operator.inputs[0].type.shape[0]\n    output_type = input_type([input_dim, op.pca_.components_.shape[1]])\n    operator.outputs[0].type = output_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The converter. One thing we need to pay attention to\nis the target opset. This information is important\nto make sure that every node is defined following the\nspecifications of that opset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def decorrelate_transformer_converter(scope, operator, container):\n    op = operator.raw_operator\n    opv = container.target_opset\n    out = operator.outputs\n\n    # We retrieve the unique input.\n    X = operator.inputs[0]\n\n    # We tell in ONNX language how to compute the unique output.\n    # op_version=opv tells which opset is requested\n    Y = OnnxSubEstimator(op.pca_, X, op_version=opv, output_names=out[:1])\n    Y.add_to(scope, container)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to let *skl2onnx* know about the new converter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "update_registered_converter(\n    DecorrelateTransformer, \"SklearnDecorrelateTransformer\",\n    decorrelate_transformer_shape_calculator,\n    decorrelate_transformer_converter)\n\n\nonx = to_onnx(dec, X.astype(numpy.float32))\n\nsess = InferenceSession(onx.SerializeToString())\n\nexp = dec.transform(X.astype(numpy.float32))\ngot = sess.run(None, {'X': X.astype(numpy.float32)})[0]\n\n\ndef diff(p1, p2):\n    p1 = p1.ravel()\n    p2 = p2.ravel()\n    d = numpy.abs(p2 - p1)\n    return d.max(), (d / numpy.abs(p1)).max()\n\n\nprint(diff(exp, got))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check it works as well with double.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx = to_onnx(dec, X.astype(numpy.float64))\n\nsess = InferenceSession(onx.SerializeToString())\n\nexp = dec.transform(X.astype(numpy.float64))\ngot = sess.run(None, {'X': X.astype(numpy.float64)})[0]\nprint(diff(exp, got))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The differences are smaller with double as expected.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final graph\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "oinf = OnnxInference(onx)\nax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}