{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Converter for WOEEncoder from categorical_encoder\n\n[WOEEncoder](https://contrib.scikit-learn.org/category_encoders/woe.html)\nis a transformer implemented in [categorical_encoder](https://contrib.scikit-learn.org/category_encoders/) and as such,\nany converter would not be included in *sklearn-onnx* which only\nimplements converters for *scikit-learn* models. Anyhow, this\nexample demonstrates how to implement a custom converter\nfor *WOEEncoder*. This code is not fully tested for all possible\ncases the original encoder can handle.\n\n.. index:: WOE, WOEEncoder\n\n## A simple example\n\nLet's take the [Iris dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html).\nEvery feature is converter into integer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom onnxruntime import InferenceSession\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import OrdinalEncoder as SklOrdinalEncoder\nfrom category_encoders import WOEEncoder, OrdinalEncoder\nfrom skl2onnx import update_registered_converter, to_onnx, get_model_alias\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom skl2onnx.common.utils import check_input_and_output_numbers\nfrom skl2onnx.algebra.onnx_ops import OnnxCast\nfrom skl2onnx.algebra.onnx_operator import OnnxSubEstimator\nfrom skl2onnx.sklapi import WOETransformer\nimport skl2onnx.sklapi.register  # noqa: F401\n\ndata = load_iris()\nX, y = data.data, data.target\nX = X.astype(np.int64)[:, :2]\ny = (y == 2).astype(np.int64)\n\nwoe = WOEEncoder(cols=[0]).fit(X, y)\nprint(woe.transform(X[:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look into the trained parameters of the model.\nIt appears that WOEEncoder uses an OrdinalEncoder\nbut not the one from scikit-learn. We need to add a\nconverter for this model tool.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"encoder\", type(woe.ordinal_encoder), woe.ordinal_encoder)\nprint(\"mapping\", woe.mapping)\nprint(\"encoder.mapping\", woe.ordinal_encoder.mapping)\nprint(\"encoder.cols\", woe.ordinal_encoder.cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom converter for OrdinalEncoder\n\nWe start from example `l-plot-custom-converter`\nand then write the conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def ordenc_to_sklearn(op_mapping):\n    \"Converts OrdinalEncoder mapping to scikit-learn OrdinalEncoder.\"\n    cats = []\n    for column_map in op_mapping:\n        col = column_map[\"col\"]\n        while len(cats) <= col:\n            cats.append(None)\n        mapping = column_map[\"mapping\"]\n        res = []\n        for i in range(mapping.shape[0]):\n            if np.isnan(mapping.index[i]):\n                continue\n            ind = mapping.iloc[i]\n            while len(res) <= ind:\n                res.append(0)\n            res[ind] = mapping.index[i]\n        cats[col] = np.array(res, dtype=np.int64)\n\n    skl_ord = SklOrdinalEncoder(categories=cats, dtype=np.int64)\n    skl_ord.categories_ = cats\n    return skl_ord\n\n\ndef ordinal_encoder_shape_calculator(operator):\n    check_input_and_output_numbers(operator, input_count_range=1, output_count_range=1)\n    input_type = operator.inputs[0].type.__class__\n    input_dim = operator.inputs[0].get_first_dimension()\n    shape = operator.inputs[0].type.shape\n    second_dim = None if len(shape) != 2 else shape[1]\n    output_type = input_type([input_dim, second_dim])\n    operator.outputs[0].type = output_type\n\n\ndef ordinal_encoder_converter(scope, operator, container):\n    op = operator.raw_operator\n    opv = container.target_opset\n    X = operator.inputs[0]\n\n    skl_ord = ordenc_to_sklearn(op.mapping)\n    cat = OnnxSubEstimator(\n        skl_ord, X, op_version=opv, output_names=operator.outputs[:1]\n    )\n    cat.add_to(scope, container)\n\n\nupdate_registered_converter(\n    OrdinalEncoder,\n    \"CategoricalEncoderOrdinalEncoder\",\n    ordinal_encoder_shape_calculator,\n    ordinal_encoder_converter,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compute the output one a short example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "enc = OrdinalEncoder(cols=[0, 1])\nenc.fit(X)\nprint(enc.transform(X[:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check the ONNX conversion produces the same results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ord_onx = to_onnx(enc, X[:1], target_opset=14)\nsess = InferenceSession(ord_onx.SerializeToString(), providers=[\"CPUExecutionProvider\"])\nprint(sess.run(None, {\"X\": X[:5]})[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That works.\n\n## Custom converter for WOEEncoder\n\nWe start from example `l-plot-custom-converter`\nand then write the conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def woeenc_to_sklearn(op_mapping):\n    \"Converts WOEEncoder mapping to scikit-learn OrdinalEncoder.\"\n    cats = []\n    ws = []\n    for column_map in op_mapping.items():\n        col = column_map[0]\n        while len(cats) <= col:\n            cats.append(\"passthrough\")\n            ws.append(None)\n        mapping = column_map[1]\n        intervals = []\n        weights = []\n        for i in range(mapping.shape[0]):\n            ind = mapping.index[i]\n            if ind < 0:\n                continue\n            intervals.append((float(ind - 1), float(ind), False, True))\n            weights.append(mapping.iloc[i])\n        cats[col] = intervals\n        ws[col] = weights\n\n    skl = WOETransformer(intervals=cats, weights=ws, onehot=False)\n    skl.fit(None)\n    return skl\n\n\ndef woe_encoder_parser(scope, model, inputs, custom_parsers=None):\n    if len(inputs) != 1:\n        raise RuntimeError(\"Unexpected number of inputs: %d != 1.\" % len(inputs))\n    if inputs[0].type is None:\n        raise RuntimeError(\"Unexpected type: %r.\" % (inputs[0],))\n    alias = get_model_alias(type(model))\n    this_operator = scope.declare_local_operator(alias, model)\n    this_operator.inputs.append(inputs[0])\n    this_operator.outputs.append(\n        scope.declare_local_variable(\"catwoe\", FloatTensorType())\n    )\n    return this_operator.outputs\n\n\ndef woe_encoder_shape_calculator(operator):\n    check_input_and_output_numbers(operator, input_count_range=1, output_count_range=1)\n    input_dim = operator.inputs[0].get_first_dimension()\n    shape = operator.inputs[0].type.shape\n    second_dim = None if len(shape) != 2 else shape[1]\n    output_type = FloatTensorType([input_dim, second_dim])\n    operator.outputs[0].type = output_type\n\n\ndef woe_encoder_converter(scope, operator, container):\n    op = operator.raw_operator\n    opv = container.target_opset\n    X = operator.inputs[0]\n\n    sub = OnnxSubEstimator(op.ordinal_encoder, X, op_version=opv)\n    cast = OnnxCast(sub, op_version=opv, to=np.float32)\n    skl_ord = woeenc_to_sklearn(op.mapping)\n    cat = OnnxSubEstimator(\n        skl_ord,\n        cast,\n        op_version=opv,\n        output_names=operator.outputs[:1],\n        input_types=[FloatTensorType()],\n    )\n    cat.add_to(scope, container)\n\n\nupdate_registered_converter(\n    WOEEncoder,\n    \"CategoricalEncoderWOEEncoder\",\n    woe_encoder_shape_calculator,\n    woe_encoder_converter,\n    parser=woe_encoder_parser,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compute the output one a short example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "woe = WOEEncoder(cols=[0, 1]).fit(X, y)\nprint(woe.transform(X[:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check the ONNX conversion produces the same results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "woe_onx = to_onnx(woe, X[:1], target_opset=14)\nsess = InferenceSession(woe_onx.SerializeToString(), providers=[\"CPUExecutionProvider\"])\nprint(sess.run(None, {\"X\": X[:5]})[0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}