{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Dataframe as an input\n\n.. index:: dataframe\n\nA pipeline usually ingests data as a matrix. It may be converted in a matrix\nif all the data share the same type. But data held in a dataframe\nhave usually multiple types, float, integer or string for categories.\nONNX also supports that case.\n\n## A dataset with categories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nimport pprint\nfrom onnxruntime import InferenceSession\nfrom pandas import DataFrame\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skl2onnx import to_onnx\nfrom skl2onnx.algebra.type_helper import guess_initial_types\n\n\ndata = DataFrame(\n    [\n        dict(CAT1=\"a\", CAT2=\"c\", num1=0.5, num2=0.6, y=0),\n        dict(CAT1=\"b\", CAT2=\"d\", num1=0.4, num2=0.8, y=1),\n        dict(CAT1=\"a\", CAT2=\"d\", num1=0.5, num2=0.56, y=0),\n        dict(CAT1=\"a\", CAT2=\"d\", num1=0.55, num2=0.56, y=1),\n        dict(CAT1=\"a\", CAT2=\"c\", num1=0.35, num2=0.86, y=0),\n        dict(CAT1=\"a\", CAT2=\"c\", num1=0.5, num2=0.68, y=1),\n    ]\n)\n\ncat_cols = [\"CAT1\", \"CAT2\"]\ntrain_data = data.drop(\"y\", axis=1)\n\n\ncategorical_transformer = Pipeline(\n    [(\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))]\n)\npreprocessor = ColumnTransformer(\n    transformers=[(\"cat\", categorical_transformer, cat_cols)], remainder=\"passthrough\"\n)\npipe = Pipeline([(\"preprocess\", preprocessor), (\"rf\", RandomForestClassifier())])\npipe.fit(train_data, data[\"y\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion to ONNX\n\nFunction *to_onnx* does not handle dataframes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx = to_onnx(pipe, train_data[:1], options={RandomForestClassifier: {\"zipmap\": False}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction with ONNX\n\n*onnxruntime* does not support dataframes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = InferenceSession(onx.SerializeToString(), providers=[\"CPUExecutionProvider\"])\ntry:\n    sess.run(None, train_data)\nexcept Exception as e:\n    print(e)\n\n# Unhide conversion logic with a dataframe\n# ++++++++++++++++++++++++++++++++++++++++\n#\n# A dataframe can be seen as a set of columns with\n# different types. That's what ONNX should see:\n# a list of inputs, the input name is the column name,\n# the input type is the column type.\n\n\ndef guess_schema_from_data(X):\n    init = guess_initial_types(X)\n    unique = set()\n    for _, col in init:\n        if len(col.shape) != 2:\n            return init\n        if col.shape[0] is not None:\n            return init\n        if len(unique) > 0 and col.__class__ not in unique:\n            return init\n        unique.add(col.__class__)\n    unique = list(unique)\n    return [(\"X\", unique[0]([None, sum(_[1].shape[1] for _ in init)]))]\n\n\ninit = guess_schema_from_data(train_data)\n\npprint.pprint(init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's use float instead.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for c in train_data.columns:\n    if c not in cat_cols:\n        train_data[c] = train_data[c].astype(numpy.float32)\n\n\ninit = guess_schema_from_data(train_data)\npprint.pprint(init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's convert with *skl2onnx* only.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx2 = to_onnx(\n    pipe, initial_types=init, options={RandomForestClassifier: {\"zipmap\": False}}\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's run it with onnxruntime.\nWe need to convert the dataframe into a dictionary\nwhere column names become keys, and column values become\nvalues.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inputs = {c: train_data[c].values.reshape((-1, 1)) for c in train_data.columns}\npprint.pprint(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inference.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess2 = InferenceSession(onx2.SerializeToString(), providers=[\"CPUExecutionProvider\"])\n\ngot2 = sess2.run(None, inputs)\n\nprint(pipe.predict(train_data))\nprint(got2[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And probilities.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(pipe.predict_proba(train_data))\nprint(got2[1])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}