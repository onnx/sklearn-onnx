{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Transfer Learning with ONNX\n\n.. index:: transfer learning, deep learning\n\nTransfer learning is common with deep learning.\nA deep learning model is used as preprocessing before\nthe output is sent to a final classifier or regressor.\nIt is not quite easy in this case to mix framework,\n:epkg:`scikit-learn` with :epkg:`pytorch`\n(or :epkg:`skorch`), the Keras API for Tensorflow,\n`tf.keras.wrappers.scikit_learn\n<https://www.tensorflow.org/api_docs/python/tf/\nkeras/wrappers/scikit_learn>`_. Every combination\nrequires work. ONNX reduces the number of platforms to\nsupport. Once the model is converted into ONNX,\nit can be inserted in any :epkg:`scikit-learn` pipeline.\n\n## Retrieve and load a model\n\nWe download one model from the :epkg:`ONNX Zoo` but the model\ncould be trained and produced by another converter library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sys\nfrom io import BytesIO\nimport onnx\nfrom mlprodict.sklapi import OnnxTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom mlinsights.plotting.gallery import plot_gallery_images\nimport matplotlib.pyplot as plt\nfrom skl2onnx.tutorial.imagenet_classes import class_names\nimport numpy\nfrom PIL import Image\nfrom onnxruntime import InferenceSession\nfrom onnxruntime.capi.onnxruntime_pybind11_state import InvalidArgument\nimport os\nimport urllib.request\n\n\ndef download_file(url, name, min_size):\n    if not os.path.exists(name):\n        print(\"download '%s'\" % url)\n        with urllib.request.urlopen(url) as u:\n            content = u.read()\n        if len(content) < min_size:\n            raise RuntimeError(\n                \"Unable to download '{}' due to\\n{}\".format(\n                    url, content))\n        print(\"downloaded %d bytes.\" % len(content))\n        with open(name, \"wb\") as f:\n            f.write(content)\n    else:\n        print(\"'%s' already downloaded\" % name)\n\n\nmodel_name = \"squeezenet1.1-7.onnx\"\nurl_name = (\"https://github.com/onnx/models/raw/main/vision/\"\n            \"classification/squeezenet/model\")\nurl_name += \"/\" + model_name\ntry:\n    download_file(url_name, model_name, 100000)\nexcept RuntimeError as e:\n    print(e)\n    sys.exit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading the ONNX file and use it on one image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = InferenceSession(model_name)\n\nfor inp in sess.get_inputs():\n    print(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model expects a series of images of size\n`[3, 224, 224]`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classifying an image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = (\"https://upload.wikimedia.org/wikipedia/commons/d/d2/\"\n       \"East_Coker_elm%2C_2.jpg\")\nimg = \"East_Coker_elm.jpg\"\ndownload_file(url, img, 100000)\n\nim0 = Image.open(img)\nim = im0.resize((224, 224))\n# im.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image to numpy and predection.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def im2array(im):\n    X = numpy.asarray(im)\n    X = X.transpose(2, 0, 1)\n    X = X.reshape(1, 3, 224, 224)\n    return X\n\n\nX = im2array(im)\nout = sess.run(None, {'data': X.astype(numpy.float32)})\nout = out[0]\n\nprint(out[0, :5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "res = list(sorted((r, class_names[i]) for i, r in enumerate(out[0])))\nprint(res[-5:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classifying more images\n\nThe initial image is rotated,\nthe answer is changing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "angles = [a * 2. for a in range(-6, 6)]\nimgs = [(angle, im0.rotate(angle).resize((224, 224)))\n        for angle in angles]\n\n\ndef classify(imgs):\n    labels = []\n    for angle, img in imgs:\n        X = im2array(img)\n        probs = sess.run(None, {'data': X.astype(numpy.float32)})[0]\n        pl = list(sorted(\n            ((r, class_names[i]) for i, r in enumerate(probs[0])),\n            reverse=True))\n        labels.append((angle, pl))\n    return labels\n\n\nclimgs = classify(imgs)\nfor angle, res in climgs:\n    print(\"angle={} - {}\".format(angle, res[:5]))\n\n\nplot_gallery_images([img[1] for img in imgs],\n                    [img[1][0][1][:15] for img in climgs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer learning in a pipeline\n\nThe proposed transfer learning consists\nusing a PCA to projet the probabilities\non a graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(model_name, 'rb') as f:\n    model_bytes = f.read()\n\npipe = Pipeline(steps=[\n    ('deep', OnnxTransformer(\n        model_bytes, runtime='onnxruntime1', change_batch_size=0)),\n    ('pca', PCA(2))\n])\n\nX_train = numpy.vstack(\n    [im2array(img) for _, img in imgs]).astype(numpy.float32)\npipe.fit(X_train)\n\nproj = pipe.transform(X_train)\nprint(proj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graph for the PCA\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\nax.plot(proj[:, 0], proj[:, 1], 'o')\nax.set_title(\"Projection of classification probabilities\")\ntext = [\"%1.0f-%s\" % (el[0], el[1][0][1]) for el in climgs]\nfor label, x, y in zip(text, proj[:, 0], proj[:, 1]):\n    ax.annotate(\n        label, xy=(x, y), xytext=(-10, 10), fontsize=8,\n        textcoords='offset points', ha='right', va='bottom',\n        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove one layer at the end\n\nThe last is often removed before the model is\ninserted in a pipeline. Let's see how to do that.\nFirst, we need the list of output for every node.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = onnx.load(BytesIO(model_bytes))\noutputs = []\nfor node in model_onnx.graph.node:\n    print(node.name, node.output)\n    outputs.extend(node.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We select one of the last one.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "selected = outputs[-3]\nprint(\"selected\", selected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we tell *OnnxTransformer* to use that\nspecific one and to flatten the output\nas the dimension is not a matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipe2 = Pipeline(steps=[\n    ('deep', OnnxTransformer(\n        model_bytes, runtime='onnxruntime1', change_batch_size=0,\n        output_name=selected, reshape=True)),\n    ('pca', PCA(2))\n])\n\ntry:\n    pipe2.fit(X_train)\nexcept InvalidArgument as e:\n    print(\"Unable to fit due to\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check that it is different.\nThe following values are the shape of the\nPCA components. The number of column is the number\nof dimensions of the outputs of the transfered\nneural network.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(pipe.steps[1][1].components_.shape,\n      pipe2.steps[1][1].components_.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "proj2 = pipe2.transform(X_train)\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\nax.plot(proj2[:, 0], proj2[:, 1], 'o')\nax.set_title(\"Second projection of classification probabilities\")\ntext = [\"%1.0f-%s\" % (el[0], el[1][0][1]) for el in climgs]\nfor label, x, y in zip(text, proj2[:, 0], proj2[:, 1]):\n    ax.annotate(\n        label, xy=(x, y), xytext=(-10, 10), fontsize=8,\n        textcoords='offset points', ha='right', va='bottom',\n        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}