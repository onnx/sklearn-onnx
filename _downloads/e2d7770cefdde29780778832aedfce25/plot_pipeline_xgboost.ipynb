{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Convert a pipeline with a XGBoost model\n\n.. index:: XGBoost\n\n*sklearn-onnx* only converts *scikit-learn* models into *ONNX*\nbut many libraries implement *scikit-learn* API so that their models\ncan be included in a *scikit-learn* pipeline. This example considers\na pipeline including a *XGBoost* model. *sklearn-onnx* can convert\nthe whole pipeline as long as it knows the converter associated to\na *XGBClassifier*. Let's see how to do it.\n\nA couple of errors might happen while trying to convert\nyour own pipeline, some of them are described\nand explained in `errors-pipeline`.\n\n## Train a XGBoost classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy\nimport matplotlib.pyplot as plt\nimport onnx\nfrom onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\nimport onnxruntime as rt\nimport sklearn\nfrom sklearn.datasets import load_iris\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport xgboost\nfrom xgboost import XGBClassifier\nimport skl2onnx\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom skl2onnx import convert_sklearn, update_registered_converter\nfrom skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes  # noqa\nimport onnxmltools\nfrom onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost  # noqa\nimport onnxmltools.convert.common.data_types\n\ndata = load_iris()\nX = data.data[:, :2]\ny = data.target\n\nind = numpy.arange(X.shape[0])\nnumpy.random.shuffle(ind)\nX = X[ind, :].copy()\ny = y[ind].copy()\n\npipe = Pipeline([('scaler', StandardScaler()),\n                 ('lgbm', XGBClassifier(n_estimators=3))])\npipe.fit(X, y)\n\n# The conversion fails but it is expected.\n\ntry:\n    convert_sklearn(pipe, 'pipeline_xgboost',\n                    [('input', FloatTensorType([None, 2]))],\n                    target_opset=12)\nexcept Exception as e:\n    print(e)\n\n# The error message tells no converter was found\n# for XGBoost models. By default, *sklearn-onnx*\n# only handles models from *scikit-learn* but it can\n# be extended to every model following *scikit-learn*\n# API as long as the module knows there exists a converter\n# for every model used in a pipeline. That's why\n# we need to register a converter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the converter for XGBClassifier\n\nThe converter is implemented in *onnxmltools*:\n`onnxmltools...XGBoost.py\n<https://github.com/onnx/onnxmltools/blob/master/onnxmltools/convert/\nxgboost/operator_converters/XGBoost.py>`_.\nand the shape calculator:\n`onnxmltools...Classifier.py\n<https://github.com/onnx/onnxmltools/blob/master/onnxmltools/convert/\nxgboost/shape_calculators/Classifier.py>`_.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we import the converter and shape calculator.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's register the new converter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "update_registered_converter(\n    XGBClassifier, 'XGBoostXGBClassifier',\n    calculate_linear_classifier_output_shapes, convert_xgboost,\n    options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert again\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = convert_sklearn(\n    pipe, 'pipeline_xgboost',\n    [('input', FloatTensorType([None, 2]))],\n    target_opset=12)\n\n# And save.\nwith open(\"pipeline_xgboost.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare the predictions\n\nPredictions with XGBoost.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"predict\", pipe.predict(X[:5]))\nprint(\"predict_proba\", pipe.predict_proba(X[:1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictions with onnxruntime.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = rt.InferenceSession(\"pipeline_xgboost.onnx\")\npred_onx = sess.run(None, {\"input\": X[:5].astype(numpy.float32)})\nprint(\"predict\", pred_onx[0])\nprint(\"predict_proba\", pred_onx[1][:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display the ONNX graph\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pydot_graph = GetPydotGraph(\n    model_onnx.graph, name=model_onnx.graph.name, rankdir=\"TB\",\n    node_producer=GetOpNodeProducer(\n        \"docstring\", color=\"yellow\",\n        fillcolor=\"yellow\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline.dot\")\n\nos.system('dot -O -Gdpi=300 -Tpng pipeline.dot')\n\nimage = plt.imread(\"pipeline.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", rt.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)\nprint(\"onnxmltools: \", onnxmltools.__version__)\nprint(\"xgboost: \", xgboost.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}