{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Convert a pipeline with a LightGBM regressor\n\n.. index:: LightGBM\n\nThe discrepancies observed when using float and TreeEnsemble operator\n(see `l-example-discrepencies-float-double`)\nexplains why the converter for *LGBMRegressor* may introduce significant\ndiscrepancies even when it is used with float tensors.\n\nLibrary *lightgbm* is implemented with double. A random forest regressor\nwith multiple trees computes its prediction by adding the prediction of\nevery tree. After being converting into ONNX, this summation becomes\n$\\left[\\sum\\right]_{i=1}^F float(T_i(x))$,\nwhere *F* is the number of trees in the forest,\n$T_i(x)$ the output of tree *i* and $\\left[\\sum\\right]$\na float addition. The discrepancy can be expressed as\n$D(x) = |\\left[\\sum\\right]_{i=1}^F float(T_i(x)) -\n\\sum_{i=1}^F T_i(x)|$.\nThis grows with the number of trees in the forest.\n\nTo reduce the impact, an option was added to split the node\n*TreeEnsembleRegressor* into multiple ones and to do a summation\nwith double this time. If we assume the node if split into *a* nodes,\nthe discrepancies then become\n$D'(x) = |\\sum_{k=1}^a \\left[\\sum\\right]_{i=1}^{F/a}\nfloat(T_{ak + i}(x)) - \\sum_{i=1}^F T_i(x)|$.\n\n## Train a LGBMRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import packaging.version as pv\nimport warnings\nimport timeit\nimport numpy\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom lightgbm import LGBMRegressor\nfrom onnxruntime import InferenceSession\nfrom skl2onnx import to_onnx, update_registered_converter\nfrom skl2onnx.common.shape_calculator import (\n    calculate_linear_regressor_output_shapes,\n)\nfrom onnxmltools import __version__ as oml_version\nfrom onnxmltools.convert.lightgbm.operator_converters.LightGbm import (\n    convert_lightgbm,\n)\n\n\nN = 1000\nX = numpy.random.randn(N, 20)\ny = numpy.random.randn(N) + numpy.random.randn(N) * 100 * numpy.random.randint(\n    0, 1, 1000\n)\n\nreg = LGBMRegressor(n_estimators=1000)\nreg.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the converter for LGBMClassifier\n\nThe converter is implemented in :epkg:`onnxmltools`:\n[onnxmltools...LightGbm.py](https://github.com/onnx/onnxmltools/blob/main/onnxmltools/convert/\nlightgbm/operator_converters/LightGbm.py).\nand the shape calculator:\n[onnxmltools...Regressor.py](https://github.com/onnx/onnxmltools/blob/main/onnxmltools/convert/\nlightgbm/shape_calculators/Regressor.py).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def skl2onnx_convert_lightgbm(scope, operator, container):\n    options = scope.get_options(operator.raw_operator)\n    if \"split\" in options:\n        if pv.Version(oml_version) < pv.Version(\"1.9.2\"):\n            warnings.warn(\n                \"Option split was released in version 1.9.2 but %s is \"\n                \"installed. It will be ignored.\" % oml_version,\n                stacklevel=0,\n            )\n        operator.split = options[\"split\"]\n    else:\n        operator.split = None\n    convert_lightgbm(scope, operator, container)\n\n\nupdate_registered_converter(\n    LGBMRegressor,\n    \"LightGbmLGBMRegressor\",\n    calculate_linear_regressor_output_shapes,\n    skl2onnx_convert_lightgbm,\n    options={\"split\": None},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert\n\nWe convert the same model following the two scenarios, one single\nTreeEnsembleRegressor node, or more. *split* parameter is the number of\ntrees per node TreeEnsembleRegressor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = to_onnx(\n    reg, X[:1].astype(numpy.float32), target_opset={\"\": 14, \"ai.onnx.ml\": 2}\n)\nmodel_onnx_split = to_onnx(\n    reg,\n    X[:1].astype(numpy.float32),\n    target_opset={\"\": 14, \"ai.onnx.ml\": 2},\n    options={\"split\": 100},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discrepancies\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = InferenceSession(\n    model_onnx.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n)\nsess_split = InferenceSession(\n    model_onnx_split.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n)\n\nX32 = X.astype(numpy.float32)\nexpected = reg.predict(X32)\ngot = sess.run(None, {\"X\": X32})[0].ravel()\ngot_split = sess_split.run(None, {\"X\": X32})[0].ravel()\n\ndisp = numpy.abs(got - expected).sum()\ndisp_split = numpy.abs(got_split - expected).sum()\n\nprint(\"sum of discrepancies 1 node\", disp)\nprint(\"sum of discrepancies split node\", disp_split, \"ratio:\", disp / disp_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The sum of the discrepancies were reduced 4, 5 times.\nThe maximum is much better too.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "disc = numpy.abs(got - expected).max()\ndisc_split = numpy.abs(got_split - expected).max()\n\nprint(\"max discrepancies 1 node\", disc)\nprint(\"max discrepancies split node\", disc_split, \"ratio:\", disc / disc_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing time\n\nThe processing time is slower but not much.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"processing time no split\",\n    timeit.timeit(lambda: sess.run(None, {\"X\": X32})[0], number=150),\n)\nprint(\n    \"processing time split\",\n    timeit.timeit(lambda: sess_split.run(None, {\"X\": X32})[0], number=150),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split influence\n\nLet's see how the sum of the discrepancies moves against\nthe parameter *split*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "res = []\nfor i in tqdm([*range(20, 170, 20), 200, 300, 400, 500]):\n    model_onnx_split = to_onnx(\n        reg,\n        X[:1].astype(numpy.float32),\n        target_opset={\"\": 14, \"ai.onnx.ml\": 2},\n        options={\"split\": i},\n    )\n    sess_split = InferenceSession(\n        model_onnx_split.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n    )\n    got_split = sess_split.run(None, {\"X\": X32})[0].ravel()\n    disc_split = numpy.abs(got_split - expected).max()\n    res.append(dict(split=i, disc=disc_split))\n\ndf = DataFrame(res).set_index(\"split\")\ndf[\"baseline\"] = disc\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, ax = plt.subplots(1, 1)\ndf.plot(\n    title=\"Sum of discrepancies against split\\nsplit = number of tree per node\",\n    ax=ax,\n)\n\n# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}