{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Black list operators when converting\n\n.. index:: black list, white list\n\nSome runtimes do not implement a runtime for every\navailable operator in ONNX. The converter does not know\nthat but it is possible to black some operators. Most of\nthe converters do not change their behaviour, they fail\nif they use a black listed operator, a couple of them\nproduces a different ONNX graph.\n\n## GaussianMixture\n\nThe first converter to change its behaviour depending on a black list\nof operators is for model *GaussianMixture*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pyquickhelper.helpgen.graphviz_helper import plot_graphviz\nfrom mlprodict.onnxrt import OnnxInference\nfrom timeit import timeit\nimport numpy\nfrom onnxruntime import InferenceSession\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom skl2onnx import to_onnx\n\ndata = load_iris()\nX_train, X_test = train_test_split(data.data)\nmodel = GaussianMixture()\nmodel.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Default conversion\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = to_onnx(\n    model, X_train[:1].astype(numpy.float32),\n    options={id(model): {'score_samples': True}},\n    target_opset=12)\nsess = InferenceSession(model_onnx.SerializeToString())\n\nxt = X_test[:5].astype(numpy.float32)\nprint(model.score_samples(xt))\nprint(sess.run(None, {'X': xt})[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the ONNX graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "oinf = OnnxInference(model_onnx)\nax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion without ReduceLogSumExp\n\nParameter *black_op* is used to tell the converter\nnot to use this operator. Let's see what the converter\nproduces in that case.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx2 = to_onnx(\n    model, X_train[:1].astype(numpy.float32),\n    options={id(model): {'score_samples': True}},\n    black_op={'ReduceLogSumExp'},\n    target_opset=12)\nsess2 = InferenceSession(model_onnx2.SerializeToString())\n\nxt = X_test[:5].astype(numpy.float32)\nprint(model.score_samples(xt))\nprint(sess2.run(None, {'X': xt})[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the ONNX graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "oinf = OnnxInference(model_onnx2)\nax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing time\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(timeit(stmt=\"sess.run(None, {'X': xt})\",\n             number=10000, globals={'sess': sess, 'xt': xt}))\n\nprint(timeit(stmt=\"sess2.run(None, {'X': xt})\",\n             number=10000, globals={'sess2': sess2, 'xt': xt}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model using ReduceLogSumExp is much faster.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## If the converter cannot convert without...\n\nMany converters do not consider the white and black lists\nof operators. If a converter fails to convert without using\na blacklisted operator (or only whitelisted operators),\n*skl2onnx* raises an error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    to_onnx(\n        model, X_train[:1].astype(numpy.float32),\n        options={id(model): {'score_samples': True}},\n        black_op={'ReduceLogSumExp', 'Add'},\n        target_opset=12)\nexcept RuntimeError as e:\n    print('Error:', e)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}