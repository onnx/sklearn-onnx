{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Walk through intermediate outputs\n\nWe reuse the example `example-complex-pipeline` and\nwalk through intermediates outputs. It is very likely a converted\nmodel gives different outputs or fails due to a custom\nconverter which is not correctly implemented.\nOne option is to look into the output of every node of the\nONNX graph.\n\n## Create and train a complex pipeline\n\nWe reuse the pipeline implemented in example\n`Column Transformer with Mixed Types\n<https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py>`_.\nThere is one change because\n`ONNX-ML Imputer\n<https://github.com/onnx/onnx/blob/master/docs/\nOperators-ml.md#ai.onnx.ml.Imputer>`_\ndoes not handle string type. This cannot be part of the final ONNX pipeline\nand must be removed. Look for comment starting with ``---`` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import skl2onnx\nimport onnx\nimport sklearn\nimport matplotlib.pyplot as plt\nimport os\nfrom onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\nfrom skl2onnx.helpers.onnx_helper import select_model_inputs_outputs\nfrom skl2onnx.helpers.onnx_helper import save_onnx_model\nfrom skl2onnx.helpers.onnx_helper import enumerate_model_node_outputs\nfrom skl2onnx.helpers.onnx_helper import load_onnx_model\nimport numpy\nimport onnxruntime as rt\nfrom skl2onnx import convert_sklearn\nimport pprint\nfrom skl2onnx.common.data_types import (\n    FloatTensorType, StringTensorType, Int64TensorType)\nimport numpy as np\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\ntitanic_url = ('https://raw.githubusercontent.com/amueller/'\n               'scipy-2017-sklearn/091d371/notebooks/datasets/titanic3.csv')\ndata = pd.read_csv(titanic_url)\nX = data.drop('survived', axis=1)\ny = data['survived']\n\n# SimpleImputer on string is not available\n# for string in ONNX-ML specifications.\n# So we do it beforehand.\nfor cat in ['embarked', 'sex', 'pclass']:\n    X[cat].fillna('missing', inplace=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nnumeric_features = ['age', 'fare']\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n\ncategorical_features = ['embarked', 'sex', 'pclass']\ncategorical_transformer = Pipeline(steps=[\n    # --- SimpleImputer is not available for strings in ONNX-ML specifications.\n    # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features),\n    ])\n\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', LogisticRegression(solver='lbfgs'))])\n\nclf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the inputs of the ONNX graph\n\n*sklearn-onnx* does not know the features used to train the model\nbut it needs to know which feature has which name.\nWe simply reuse the dataframe column definition.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(X_train.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def convert_dataframe_schema(df, drop=None):\n    inputs = []\n    for k, v in zip(df.columns, df.dtypes):\n        if drop is not None and k in drop:\n            continue\n        if v == 'int64':\n            t = Int64TensorType([None, 1])\n        elif v == 'float64':\n            t = FloatTensorType([None, 1])\n        else:\n            t = StringTensorType([None, 1])\n        inputs.append((k, t))\n    return inputs\n\n\ninputs = convert_dataframe_schema(X_train)\n\npprint.pprint(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging single column into vectors is not\nthe most efficient way to compute the prediction.\nIt could be done before converting the pipeline into a graph.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert the pipeline into ONNX\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    model_onnx = convert_sklearn(clf, 'pipeline_titanic', inputs,\n                                 target_opset=12)\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*scikit-learn* does implicit conversions when it can.\n*sklearn-onnx* does not. The ONNX version of *OneHotEncoder*\nmust be applied on columns of the same type.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train['pclass'] = X_train['pclass'].astype(str)\nX_test['pclass'] = X_test['pclass'].astype(str)\nwhite_list = numeric_features + categorical_features\nto_drop = [c for c in X_train.columns if c not in white_list]\ninputs = convert_dataframe_schema(X_train, to_drop)\n\nmodel_onnx = convert_sklearn(clf, 'pipeline_titanic', inputs,\n                             target_opset=12)\n\n\n# And save.\nwith open(\"pipeline_titanic.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare the predictions\n\nFinal step, we need to ensure the converted model\nproduces the same predictions, labels and probabilities.\nLet's start with *scikit-learn*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"predict\", clf.predict(X_test[:5]))\nprint(\"predict_proba\", clf.predict_proba(X_test[:1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictions with onnxruntime.\nWe need to remove the dropped columns and to change\nthe double vectors into float vectors as *onnxruntime*\ndoes not support double floats.\n*onnxruntime* does not accept *dataframe*.\ninputs must be given as a list of dictionary.\nLast detail, every column was described  not really as a vector\nbut as a matrix of one column which explains the last line\nwith the *reshape*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_test2 = X_test.drop(to_drop, axis=1)\ninputs = {c: X_test2[c].values for c in X_test2.columns}\nfor c in numeric_features:\n    inputs[c] = inputs[c].astype(np.float32)\nfor k in inputs:\n    inputs[k] = inputs[k].reshape((inputs[k].shape[0], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are ready to run *onnxruntime*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = rt.InferenceSession(\"pipeline_titanic.onnx\")\npred_onx = sess.run(None, inputs)\nprint(\"predict\", pred_onx[0][:5])\nprint(\"predict_proba\", pred_onx[1][:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute intermediate outputs\n\nUnfortunately, there is actually no way to ask\n*onnxruntime* to retrieve the output of intermediate nodes.\nWe need to modifies the *ONNX* before it is given to *onnxruntime*.\nLet's see first the list of intermediate output.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = load_onnx_model(\"pipeline_titanic.onnx\")\nfor out in enumerate_model_node_outputs(model_onnx):\n    print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not that easy to tell which one is what as the *ONNX*\nhas more operators than the original *scikit-learn* pipelines.\nThe graph at `l-plot-complex-pipeline-graph`\nhelps up to find the outputs of both numerical\nand textual pipeline: *variable1*, *variable2*.\nLet's look into the numerical pipeline first.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_onnx = select_model_inputs_outputs(model_onnx, 'variable1')\nsave_onnx_model(num_onnx, \"pipeline_titanic_numerical.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compute the numerical features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = rt.InferenceSession(\"pipeline_titanic_numerical.onnx\")\nnumX = sess.run(None, inputs)\nprint(\"numerical features\", numX[0][:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do the same for the textual features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(model_onnx)\ntext_onnx = select_model_inputs_outputs(model_onnx, 'variable2')\nsave_onnx_model(text_onnx, \"pipeline_titanic_textual.onnx\")\nsess = rt.InferenceSession(\"pipeline_titanic_textual.onnx\")\nnumT = sess.run(None, inputs)\nprint(\"textual features\", numT[0][:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display the sub-ONNX graph\n\nFinally, let's see both subgraphs. First, numerical pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pydot_graph = GetPydotGraph(\n    num_onnx.graph, name=num_onnx.graph.name, rankdir=\"TB\",\n    node_producer=GetOpNodeProducer(\n        \"docstring\", color=\"yellow\", fillcolor=\"yellow\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline_titanic_num.dot\")\n\nos.system('dot -O -Gdpi=300 -Tpng pipeline_titanic_num.dot')\n\nimage = plt.imread(\"pipeline_titanic_num.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then textual pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pydot_graph = GetPydotGraph(\n    text_onnx.graph, name=text_onnx.graph.name, rankdir=\"TB\",\n    node_producer=GetOpNodeProducer(\n        \"docstring\", color=\"yellow\", fillcolor=\"yellow\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline_titanic_text.dot\")\n\nos.system('dot -O -Gdpi=300 -Tpng pipeline_titanic_text.dot')\n\nimage = plt.imread(\"pipeline_titanic_text.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", rt.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}