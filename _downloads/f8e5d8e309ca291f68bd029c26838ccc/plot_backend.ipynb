{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# ONNX Runtime Backend for ONNX\n\n.. index:: backend\n\n*ONNX Runtime* extends the\n`onnx backend API <https://github.com/onnx/onnx/blob/master/docs/\nImplementingAnOnnxBackend.md>`_\nto run predictions using this runtime.\nLet's use the API to compute the prediction\nof a simple logistic regression model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import skl2onnx\nimport onnxruntime\nimport onnx\nimport sklearn\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\nimport numpy\nfrom onnxruntime import get_device\nimport numpy as np\nimport onnxruntime.backend as backend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create an ONNX graph first.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = load_iris()\nX, Y = data.data, data.target\nlogreg = LogisticRegression(C=1e5).fit(X, Y)\nmodel = skl2onnx.to_onnx(logreg, X.astype(np.float32))\nname = \"logreg_iris.onnx\"\nwith open(name, \"wb\") as f:\n    f.write(model.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's use ONNX backend API to test it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = onnx.load(name)\nrep = backend.prepare(model, 'CPU')\nx = np.array([[-1.0, -2.0, 5.0, 6.0],\n              [-1.0, -2.0, -3.0, -4.0],\n              [-1.0, -2.0, 7.0, 8.0]],\n             dtype=np.float32)\nlabel, proba = rep.run(x)\nprint(\"label={}\".format(label))\nprint(\"probabilities={}\".format(proba))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The device depends on how the package was compiled,\nGPU or CPU.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(get_device())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The backend can also directly load the model\nwithout using *onnx*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rep = backend.prepare(name, 'CPU')\nx = np.array([[-1.0, -2.0, -3.0, -4.0],\n              [-1.0, -2.0, -3.0, -4.0],\n              [-1.0, -2.0, -3.0, -4.0]],\n             dtype=np.float32)\nlabel, proba = rep.run(x)\nprint(\"label={}\".format(label))\nprint(\"probabilities={}\".format(proba))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The backend API is implemented by other frameworks\nand makes it easier to switch between multiple runtimes\nwith the same API.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", onnxruntime.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}