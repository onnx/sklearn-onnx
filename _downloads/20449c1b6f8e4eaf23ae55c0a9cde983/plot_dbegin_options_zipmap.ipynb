{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Choose appropriate output of a classifier\n\nA scikit-learn classifier usually returns a matrix of probabilities.\nBy default, *sklearn-onnx* converts that matrix\ninto a list of dictionaries where each probabily is mapped\nto its class id or name. That mechanism retains the class names\nbut is slower. Let's see what other options are available.\n\n## Train a model and convert it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from timeit import repeat\nimport numpy\nimport sklearn\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nimport onnxruntime as rt\nimport onnx\nimport skl2onnx\nfrom skl2onnx import to_onnx\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputClassifier\n\niris = load_iris()\nX, y = iris.data, iris.target\nX = X.astype(numpy.float32)\ny = y * 2 + 10  # to get labels different from [0, 1, 2]\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nclr = LogisticRegression(max_iter=500)\nclr.fit(X_train, y_train)\nprint(clr)\n\nonx = to_onnx(clr, X_train, target_opset=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Default behaviour: zipmap=True\n\nThe output type for the probabilities is a list of\ndictionaries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = rt.InferenceSession(onx.SerializeToString(), providers=[\"CPUExecutionProvider\"])\nres = sess.run(None, {\"X\": X_test})\nprint(res[1][:2])\nprint(\"probabilities type:\", type(res[1]))\nprint(\"type for the first observations:\", type(res[1][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option zipmap=False\n\nProbabilities are now a matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "options = {id(clr): {\"zipmap\": False}}\nonx2 = to_onnx(clr, X_train, options=options, target_opset=12)\n\nsess2 = rt.InferenceSession(\n    onx2.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n)\nres2 = sess2.run(None, {\"X\": X_test})\nprint(res2[1][:2])\nprint(\"probabilities type:\", type(res2[1]))\nprint(\"type for the first observations:\", type(res2[1][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option zipmap='columns'\n\nThis options removes the final operator ZipMap and splits\nthe probabilities into columns. The final model produces\none output for the label, and one output per class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "options = {id(clr): {\"zipmap\": \"columns\"}}\nonx3 = to_onnx(clr, X_train, options=options, target_opset=12)\n\nsess3 = rt.InferenceSession(\n    onx3.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n)\nres3 = sess3.run(None, {\"X\": X_test})\nfor i, out in enumerate(sess3.get_outputs()):\n    print(\n        \"output: '{}' shape={} values={}...\".format(\n            out.name, res3[i].shape, res3[i][:2]\n        )\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let's compare prediction time\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Average time with ZipMap:\")\nprint(sum(repeat(lambda: sess.run(None, {\"X\": X_test}), number=100, repeat=10)) / 10)\n\nprint(\"Average time without ZipMap:\")\nprint(sum(repeat(lambda: sess2.run(None, {\"X\": X_test}), number=100, repeat=10)) / 10)\n\nprint(\"Average time without ZipMap but with columns:\")\nprint(sum(repeat(lambda: sess3.run(None, {\"X\": X_test}), number=100, repeat=10)) / 10)\n\n# The prediction is much faster without ZipMap\n# on this example.\n# The optimisation is even faster when the classes\n# are described with strings and not integers\n# as the final result (list of dictionaries) may copy\n# many times the same information with onnxruntime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option zimpap=False and output_class_labels=True\n\nOption `zipmap=False` seems a better choice because it is\nmuch faster but labels are lost in the process. Option\n`output_class_labels` can be used to expose the labels\nas a third output.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "options = {id(clr): {\"zipmap\": False, \"output_class_labels\": True}}\nonx4 = to_onnx(clr, X_train, options=options, target_opset=12)\n\nsess4 = rt.InferenceSession(\n    onx4.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n)\nres4 = sess4.run(None, {\"X\": X_test})\nprint(res4[1][:2])\nprint(\"probabilities type:\", type(res4[1]))\nprint(\"class labels:\", res4[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Processing time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Average time without ZipMap but with output_class_labels:\")\nprint(sum(repeat(lambda: sess4.run(None, {\"X\": X_test}), number=100, repeat=10)) / 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MultiOutputClassifier\n\nThis model is equivalent to several classifiers, one for every label\nto predict. Instead of returning a matrix of probabilities, it returns\na sequence of matrices. Let's first modify the labels to get\na problem for a MultiOutputClassifier.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = numpy.vstack([y, y + 100]).T\ny[::5, 1] = 1000  # Let's a fourth class.\nprint(y[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's train a MultiOutputClassifier.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\nclr = MultiOutputClassifier(LogisticRegression(max_iter=500))\nclr.fit(X_train, y_train)\nprint(clr)\n\nonx5 = to_onnx(clr, X_train, target_opset=12)\n\nsess5 = rt.InferenceSession(\n    onx5.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n)\nres5 = sess5.run(None, {\"X\": X_test[:3]})\nprint(res5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Option zipmap is ignored. Labels are missing but they can be\nadded back as a third output.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx6 = to_onnx(\n    clr,\n    X_train,\n    target_opset=12,\n    options={\"zipmap\": False, \"output_class_labels\": True},\n)\n\nsess6 = rt.InferenceSession(\n    onx6.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n)\nres6 = sess6.run(None, {\"X\": X_test[:3]})\nprint(\"predicted labels\", res6[0])\nprint(\"predicted probabilies\", res6[1])\nprint(\"class labels\", res6[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", rt.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}