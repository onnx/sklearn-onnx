{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Discrepencies with StandardScaler\n\nA [StandardScaler](https://scikit-learn.org/stable/modules/\ngenerated/sklearn.preprocessing.StandardScaler.html) does\na very basic scaling. The conversion in ONNX assumes that\n``(x / y)`` is equivalent to ``x * ( 1 / y)`` but that's not\ntrue with float or double (see\n[Will the compiler optimize division into multiplication](https://stackoverflow.com/questions/35506226/\nwill-the-compiler-optimize-division-into-multiplication)).\nEven if the difference is small,\nit may introduce discrepencies if the next step is\na decision tree. One small difference and the decision\nfollows another path in the tree. Let's see how to solve\nthat issue.\n\n## An example with fails\n\nThis is not a typical example, it is build to make it fails\nbased on the assumption ``(x / y)`` is usually different from\n``x * ( 1 / y)`` on a computer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import onnxruntime\nimport onnx\nimport os\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\nfrom onnxruntime import InferenceSession\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeRegressor\nfrom skl2onnx.sklapi import CastTransformer\nfrom skl2onnx import to_onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The weird data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = make_regression(10000, 10, random_state=3)\nX_train, X_test, y_train, _ = train_test_split(X, y, random_state=3)\nXi_train, yi_train = X_train.copy(), y_train.copy()\nXi_test = X_test.copy()\nfor i in range(X.shape[1]):\n    Xi_train[:, i] = (Xi_train[:, i] * math.pi * 2**i).astype(np.int64)\n    Xi_test[:, i] = (Xi_test[:, i] * math.pi * 2**i).astype(np.int64)\nmax_depth = 10\nXi_test = Xi_test.astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model1 = Pipeline(\n    [(\"scaler\", StandardScaler()), (\"dt\", DecisionTreeRegressor(max_depth=max_depth))]\n)\nmodel1.fit(Xi_train, yi_train)\nexp1 = model1.predict(Xi_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conversion into ONNX.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx1 = to_onnx(model1, X_train[:1].astype(np.float32), target_opset=15)\nsess1 = InferenceSession(onx1.SerializeToString(), providers=[\"CPUExecutionProvider\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the maximum difference.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "got1 = sess1.run(None, {\"X\": Xi_test})[0]\n\n\ndef maxdiff(a1, a2):\n    d = np.abs(a1.ravel() - a2.ravel())\n    return d.max()\n\n\nmd1 = maxdiff(exp1, got1)\nprint(md1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pydot_graph = GetPydotGraph(\n    onx1.graph,\n    name=onx1.graph.name,\n    rankdir=\"TB\",\n    node_producer=GetOpNodeProducer(\n        \"docstring\", color=\"yellow\", fillcolor=\"yellow\", style=\"filled\"\n    ),\n)\npydot_graph.write_dot(\"cast1.dot\")\n\nos.system(\"dot -O -Gdpi=300 -Tpng cast1.dot\")\n\nimage = plt.imread(\"cast1.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## New pipeline\n\nFixing the conversion requires to replace ``(x * (1 / y)``\nby ``(x / y)`` and this division must happen in double.\nBy default, the *sklearn-onnx* assumes every\ncomputer should happen in float. [ONNX 1.7 specifications](https://github.com/onnx/onnx/blob/main/docs/\nOperators-ml.md#ai.onnx.ml.Scaler)\ndoes not support double scaling (input and output does,\nbut not the parameters). The solution needs to\nchange the conversion (remove node Scaler by using option\n`'div'`) and to use double by inserting an explicit\nCast.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model2 = Pipeline(\n    [\n        (\"cast64\", CastTransformer(dtype=np.float64)),\n        (\"scaler\", StandardScaler()),\n        (\"cast\", CastTransformer()),\n        (\"dt\", DecisionTreeRegressor(max_depth=max_depth)),\n    ]\n)\n\nmodel2.fit(Xi_train, yi_train)\nexp2 = model2.predict(Xi_test)\n\nonx2 = to_onnx(\n    model2,\n    X_train[:1].astype(np.float32),\n    options={StandardScaler: {\"div\": \"div_cast\"}},\n    target_opset=15,\n)\n\nsess2 = InferenceSession(onx2.SerializeToString(), providers=[\"CPUExecutionProvider\"])\ngot2 = sess2.run(None, {\"X\": Xi_test})[0]\nmd2 = maxdiff(exp2, got2)\n\nprint(md2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pydot_graph = GetPydotGraph(\n    onx2.graph,\n    name=onx2.graph.name,\n    rankdir=\"TB\",\n    node_producer=GetOpNodeProducer(\n        \"docstring\", color=\"yellow\", fillcolor=\"yellow\", style=\"filled\"\n    ),\n)\npydot_graph.write_dot(\"cast2.dot\")\n\nos.system(\"dot -O -Gdpi=300 -Tpng cast2.dot\")\n\nimage = plt.imread(\"cast2.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sklearn\n\nprint(\"numpy:\", np.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nimport skl2onnx\n\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", onnxruntime.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}