{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Change the number of outputs by adding a parser\n\n.. index:: parser\n\nBy default, :epkg:`sklearn-onnx` assumes that a classifier\nhas two outputs (label and probabilities), a regressor\nhas one output (prediction), a transform has one output\n(the transformed data). What if it is not the case?\nThe following example creates a custom converter\nand a custom parser which defines the number of outputs\nexpected by the converted model.\n\nExample `l-plot-custom-options` shows a converter\nwhich selects two ways to compute the same outputs.\nIn this one, the converter produces both. That would not\nbe a very efficient converter but that's just for the sake\nof using a parser. By default, a transformer only returns\none output but both are needed.\n\n## A new transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pyquickhelper.helpgen.graphviz_helper import plot_graphviz\nfrom mlprodict.onnxrt import OnnxInference\nimport numpy\nfrom onnxruntime import InferenceSession\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.datasets import load_iris\nfrom skl2onnx import update_registered_converter\nfrom skl2onnx.common.data_types import guess_numpy_type\nfrom skl2onnx.algebra.onnx_ops import (\n    OnnxSub, OnnxMatMul, OnnxGemm)\nfrom skl2onnx import to_onnx, get_model_alias\n\n\nclass DecorrelateTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"\n    Decorrelates correlated gaussian features.\n\n    :param alpha: avoids non inversible matrices\n        by adding *alpha* identity matrix\n\n    *Attributes*\n\n    * `self.mean_`: average\n    * `self.coef_`: square root of the coveriance matrix\n    \"\"\"\n\n    def __init__(self, alpha=0.):\n        BaseEstimator.__init__(self)\n        TransformerMixin.__init__(self)\n        self.alpha = alpha\n\n    def fit(self, X, y=None, sample_weights=None):\n        if sample_weights is not None:\n            raise NotImplementedError(\n                \"sample_weights != None is not implemented.\")\n        self.mean_ = numpy.mean(X, axis=0, keepdims=True)\n        X = X - self.mean_\n        V = X.T @ X / X.shape[0]\n        if self.alpha != 0:\n            V += numpy.identity(V.shape[0]) * self.alpha\n        L, P = numpy.linalg.eig(V)\n        Linv = L ** (-0.5)\n        diag = numpy.diag(Linv)\n        root = P @ diag @ P.transpose()\n        self.coef_ = root\n        return self\n\n    def transform(self, X):\n        return (X - self.mean_) @ self.coef_\n\n\ndata = load_iris()\nX = data.data\n\ndec = DecorrelateTransformer()\ndec.fit(X)\npred = dec.transform(X[:5])\nprint(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion into ONNX with two outputs\n\nLet's try to convert it and see what happens.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def decorrelate_transformer_shape_calculator(operator):\n    op = operator.raw_operator\n    input_type = operator.inputs[0].type.__class__\n    input_dim = operator.inputs[0].type.shape[0]\n    output_type = input_type([input_dim, op.coef_.shape[1]])\n    operator.outputs[0].type = output_type\n\n\ndef decorrelate_transformer_converter(scope, operator, container):\n    op = operator.raw_operator\n    opv = container.target_opset\n    out = operator.outputs\n\n    X = operator.inputs[0]\n\n    dtype = guess_numpy_type(X.type)\n\n    Y1 = OnnxMatMul(\n        OnnxSub(X, op.mean_.astype(dtype), op_version=opv),\n        op.coef_.astype(dtype),\n        op_version=opv, output_names=out[:1])\n\n    Y2 = OnnxGemm(X, op.coef_.astype(dtype),\n                  (- op.mean_ @ op.coef_).astype(dtype),\n                  op_version=opv, alpha=1., beta=1.,\n                  output_names=out[1:2])\n\n    Y1.add_to(scope, container)\n    Y2.add_to(scope, container)\n\n\ndef decorrelate_transformer_parser(\n        scope, model, inputs, custom_parsers=None):\n    alias = get_model_alias(type(model))\n    this_operator = scope.declare_local_operator(alias, model)\n\n    # inputs\n    this_operator.inputs.append(inputs[0])\n\n    # outputs\n    cls_type = inputs[0].type.__class__\n    val_y1 = scope.declare_local_variable('nogemm', cls_type())\n    val_y2 = scope.declare_local_variable('gemm', cls_type())\n    this_operator.outputs.append(val_y1)\n    this_operator.outputs.append(val_y2)\n\n    # ends\n    return this_operator.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The registration needs to declare the parser as well.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "update_registered_converter(\n    DecorrelateTransformer, \"SklearnDecorrelateTransformer\",\n    decorrelate_transformer_shape_calculator,\n    decorrelate_transformer_converter,\n    parser=decorrelate_transformer_parser)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx = to_onnx(dec, X.astype(numpy.float32),\n              target_opset=14)\n\nsess = InferenceSession(onx.SerializeToString())\n\nexp = dec.transform(X.astype(numpy.float32))\nresults = sess.run(None, {'X': X.astype(numpy.float32)})\ny1 = results[0]\ny2 = results[1]\n\n\ndef diff(p1, p2):\n    p1 = p1.ravel()\n    p2 = p2.ravel()\n    d = numpy.abs(p2 - p1)\n    return d.max(), (d / numpy.abs(p1)).max()\n\n\nprint(diff(exp, y1))\nprint(diff(exp, y2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It works. The final looks like the following.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "oinf = OnnxInference(onx, runtime=\"python_compiled\")\nprint(oinf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final graph\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}