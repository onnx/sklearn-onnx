{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Convert a pipeline with ColumnTransformer\n\n*scikit-learn* recently shipped\n`ColumnTransformer <https://scikit-learn.org/stable/modules/\ngenerated/sklearn.compose.ColumnTransformer.html>`_\nwhich lets the user define complex pipeline where each\ncolumn may be preprocessed with a different transformer.\n*sklearn-onnx* still works in this case as shown in Section\n`l-complex-pipeline`.\n\n## Create and train a complex pipeline\n\nWe reuse the pipeline implemented in example\n`Column Transformer with Mixed Types\n<https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py>`_.\nThere is one change because\n`ONNX-ML Imputer\n<https://github.com/onnx/onnx/blob/master/docs/\nOperators-ml.md#ai.onnx.ml.Imputer>`_\ndoes not handle string type. This cannot be part of the final ONNX pipeline\nand must be removed. Look for comment starting with ``---`` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport pprint\nimport pandas as pd\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nimport onnx\nfrom onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\nimport onnxruntime as rt\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport skl2onnx\nfrom skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import FloatTensorType, StringTensorType\nfrom skl2onnx.common.data_types import Int64TensorType\n\ntitanic_url = ('https://raw.githubusercontent.com/amueller/'\n               'scipy-2017-sklearn/091d371/notebooks/datasets/titanic3.csv')\ndata = pd.read_csv(titanic_url)\nX = data.drop('survived', axis=1)\ny = data['survived']\nprint(data.dtypes)\n\n# SimpleImputer on string is not available for\n# string in ONNX-ML specifications.\n# So we do it beforehand.\nfor cat in ['embarked', 'sex', 'pclass']:\n    X[cat].fillna('missing', inplace=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nnumeric_features = ['age', 'fare']\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n\ncategorical_features = ['embarked', 'sex', 'pclass']\ncategorical_transformer = Pipeline(steps=[\n    # --- SimpleImputer is not available for strings in ONNX-ML specifications.\n    # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features),\n    ])\n\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', LogisticRegression(solver='lbfgs'))])\n\n\nclf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the inputs of the ONNX graph\n\n*sklearn-onnx* does not know the features used to train the model\nbut it needs to know which feature has which name.\nWe simply reuse the dataframe column definition.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(X_train.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def convert_dataframe_schema(df, drop=None):\n    inputs = []\n    for k, v in zip(df.columns, df.dtypes):\n        if drop is not None and k in drop:\n            continue\n        if v == 'int64':\n            t = Int64TensorType([None, 1])\n        elif v == 'float64':\n            t = FloatTensorType([None, 1])\n        else:\n            t = StringTensorType([None, 1])\n        inputs.append((k, t))\n    return inputs\n\n\ninitial_inputs = convert_dataframe_schema(X_train)\n\npprint.pprint(initial_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging single column into vectors is not\nthe most efficient way to compute the prediction.\nIt could be done before converting the pipeline into a graph.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert the pipeline into ONNX\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    model_onnx = convert_sklearn(clf, 'pipeline_titanic', initial_inputs,\n                                 target_opset=12)\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictions are more efficient if the graph is small.\nThat's why the converter checks that there is no unused input.\nThey need to be removed from the graph inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "to_drop = {'parch', 'sibsp', 'cabin', 'ticket',\n           'name', 'body', 'home.dest', 'boat'}\ninitial_inputs = convert_dataframe_schema(X_train, to_drop)\ntry:\n    model_onnx = convert_sklearn(clf, 'pipeline_titanic', initial_inputs,\n                                 target_opset=12)\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*scikit-learn* does implicit conversions when it can.\n*sklearn-onnx* does not. The ONNX version of *OneHotEncoder*\nmust be applied on columns of the same type.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "initial_inputs = convert_dataframe_schema(X_train, to_drop)\n\nmodel_onnx = convert_sklearn(clf, 'pipeline_titanic', initial_inputs,\n                             target_opset=12)\n\n\n# And save.\nwith open(\"pipeline_titanic.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare the predictions\n\nFinal step, we need to ensure the converted model\nproduces the same predictions, labels and probabilities.\nLet's start with *scikit-learn*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"predict\", clf.predict(X_test[:5]))\nprint(\"predict_proba\", clf.predict_proba(X_test[:2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictions with onnxruntime.\nWe need to remove the dropped columns and to change\nthe double vectors into float vectors as *onnxruntime*\ndoes not support double floats.\n*onnxruntime* does not accept *dataframe*.\ninputs must be given as a list of dictionary.\nLast detail, every column was described  not really as a vector\nbut as a matrix of one column which explains the last line\nwith the *reshape*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_test2 = X_test.drop(to_drop, axis=1)\ninputs = {c: X_test2[c].values for c in X_test2.columns}\nfor c in numeric_features:\n    inputs[c] = inputs[c].astype(np.float32)\nfor k in inputs:\n    inputs[k] = inputs[k].reshape((inputs[k].shape[0], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are ready to run *onnxruntime*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = rt.InferenceSession(\"pipeline_titanic.onnx\")\npred_onx = sess.run(None, inputs)\nprint(\"predict\", pred_onx[0][:5])\nprint(\"predict_proba\", pred_onx[1][:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output of onnxruntime is a list of dictionaries.\nLet's swith to an array but that requires to convert again with\nan additional option zipmap.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = convert_sklearn(clf, 'pipeline_titanic', initial_inputs,\n                             target_opset=12,\n                             options={id(clf): {'zipmap': False}})\nwith open(\"pipeline_titanic_nozipmap.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())\n\nsess = rt.InferenceSession(\"pipeline_titanic_nozipmap.onnx\")\npred_onx = sess.run(None, inputs)\nprint(\"predict\", pred_onx[0][:5])\nprint(\"predict_proba\", pred_onx[1][:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check they are the same.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert_almost_equal(clf.predict_proba(X_test), pred_onx[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Display the ONNX graph\n\nFinally, let's see the graph converted with *sklearn-onnx*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pydot_graph = GetPydotGraph(model_onnx.graph, name=model_onnx.graph.name,\n                            rankdir=\"TB\",\n                            node_producer=GetOpNodeProducer(\"docstring\",\n                                                            color=\"yellow\",\n                                                            fillcolor=\"yellow\",\n                                                            style=\"filled\"))\npydot_graph.write_dot(\"pipeline_titanic.dot\")\n\nos.system('dot -O -Gdpi=300 -Tpng pipeline_titanic.dot')\n\nimage = plt.imread(\"pipeline_titanic.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"numpy:\", np.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", rt.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}