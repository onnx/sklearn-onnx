{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Investigate a pipeline\n\nThe following example shows how to look into a converted\nmodels and easily find errors at every step of the pipeline.\n\n## Create a pipeline\n\nWe reuse the pipeline implemented in example\n`Pipelining: chaining a PCA and a logistic regression\n<https://scikit-learn.org/stable/auto_examples/\ncompose/plot_digits_pipe.html>`_.\nThere is one change because\n`ONNX-ML Imputer\n<https://github.com/onnx/onnx/blob/master/docs/\nOperators-ml.md#ai.onnx.ml.Imputer>`_\ndoes not handle string type. This cannot be part of the final ONNX pipeline\nand must be removed. Look for comment starting with ``---`` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import skl2onnx\nimport onnx\nimport sklearn\nimport numpy\nimport pickle\nfrom skl2onnx.helpers import collect_intermediate_steps\nimport onnxruntime as rt\nfrom onnxconverter_common.data_types import FloatTensorType\nfrom skl2onnx import convert_sklearn\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import datasets\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\n\npipe = Pipeline(steps=[('pca', PCA()),\n                       ('logistic', LogisticRegression())])\n\ndigits = datasets.load_digits()\nX_digits = digits.data[:1000]\ny_digits = digits.target[:1000]\n\npipe.fit(X_digits, y_digits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion to ONNX\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "initial_types = [('input', FloatTensorType((None, X_digits.shape[1])))]\nmodel_onnx = convert_sklearn(pipe, initial_types=initial_types,\n                             target_opset=12)\n\nsess = rt.InferenceSession(model_onnx.SerializeToString())\nprint(\"skl predict_proba\")\nprint(pipe.predict_proba(X_digits[:2]))\nonx_pred = sess.run(None, {'input': X_digits[:2].astype(np.float32)})[1]\ndf = pd.DataFrame(onx_pred)\nprint(\"onnx predict_proba\")\nprint(df.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intermediate steps\n\nLet's imagine the final output is wrong and we need\nto look into each component of the pipeline which one\nis failing. The following method modifies the scikit-learn\npipeline to steal the intermediate outputs and produces\nan smaller ONNX graph for every operator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "steps = collect_intermediate_steps(pipe, \"pipeline\",\n                                   initial_types)\n\nassert len(steps) == 2\n\npipe.predict_proba(X_digits[:2])\n\nfor i, step in enumerate(steps):\n    onnx_step = step['onnx_step']\n    sess = rt.InferenceSession(onnx_step.SerializeToString())\n    onnx_outputs = sess.run(None, {'input': X_digits[:2].astype(np.float32)})\n    skl_outputs = step['model']._debug.outputs\n    print(\"step 1\", type(step['model']))\n    print(\"skl outputs\")\n    print(skl_outputs)\n    print(\"onnx outputs\")\n    print(onnx_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pickle\n\nEach steps is a separate model in the pipeline.\nIt can be pickle independetly from the others.\nAttribute *_debug* contains all the information\nneeded to *replay* the prediction of the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "to_save = {\n    'model': steps[1]['model'],\n    'data_input': steps[1]['model']._debug.inputs,\n    'data_output': steps[1]['model']._debug.outputs,\n    'inputs': steps[1]['inputs'],\n    'outputs': steps[1]['outputs'],\n}\ndel steps[1]['model']._debug\n\nwith open('classifier.pkl', 'wb') as f:\n    pickle.dump(to_save, f)\n\nwith open('classifier.pkl', 'rb') as f:\n    restored = pickle.load(f)\n\nprint(restored['model'].predict_proba(restored['data_input']['predict_proba']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", rt.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}