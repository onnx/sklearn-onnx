
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples\plot_custom_parser.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_custom_parser.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_custom_parser.py:


.. _l-custom-parser:

When a custom model is neither a classifier nor a regressor
===========================================================

*scikit-learn*'s API specifies that a regressor produces one
outputs and a classifier produces two
outputs, predicted labels and probabilities. The goal here is
to add a third result which tells if the probability is
above a given threshold. That's implemented in method
*validate*.

.. contents::
    :local:

Iris and scoring
++++++++++++++++

A new class is created, it trains any classifier and implements
the method *validate* mentioned above.

.. GENERATED FROM PYTHON SOURCE LINES 26-87

.. code-block:: default

    import inspect
    import numpy as np
    import skl2onnx
    import onnx
    import sklearn
    from sklearn.base import ClassifierMixin, BaseEstimator, clone
    from sklearn.datasets import load_iris
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from skl2onnx import update_registered_converter
    import os
    from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer
    import onnxruntime as rt
    from onnxconverter_common.onnx_ops import (
        apply_identity, apply_cast, apply_greater
    )
    from skl2onnx import to_onnx, get_model_alias
    from skl2onnx.proto import onnx_proto
    from skl2onnx.common._registration import get_shape_calculator
    from skl2onnx.common.data_types import FloatTensorType, Int64TensorType
    import matplotlib.pyplot as plt


    class ValidatorClassifier(BaseEstimator, ClassifierMixin):

        def __init__(self, estimator=None, threshold=0.75):
            ClassifierMixin.__init__(self)
            BaseEstimator.__init__(self)
            if estimator is None:
                estimator = LogisticRegression(solver='liblinear')
            self.estimator = estimator
            self.threshold = threshold

        def fit(self, X, y, sample_weight=None):
            sig = inspect.signature(self.estimator.fit)
            if 'sample_weight' in sig.parameters:
                self.estimator_ = clone(self.estimator).fit(
                    X, y, sample_weight=sample_weight)
            else:
                self.estimator_ = clone(self.estimator).fit(X, y)
            return self

        def predict(self, X):
            return self.estimator_.predict(X)

        def predict_proba(self, X):
            return self.estimator_.predict_proba(X)

        def validate(self, X):
            pred = self.predict_proba(X)
            mx = pred.max(axis=1)
            return (mx >= self.threshold) * 1


    data = load_iris()
    X, y = data.data, data.target
    X_train, X_test, y_train, y_test = train_test_split(X, y)

    model = ValidatorClassifier()
    model.fit(X_train, y_train)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-8" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>ValidatorClassifier(estimator=LogisticRegression(solver=&#x27;liblinear&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-30" type="checkbox" ><label for="sk-estimator-id-30" class="sk-toggleable__label sk-toggleable__label-arrow">ValidatorClassifier</label><div class="sk-toggleable__content"><pre>ValidatorClassifier(estimator=LogisticRegression(solver=&#x27;liblinear&#x27;))</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-31" type="checkbox" ><label for="sk-estimator-id-31" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-32" type="checkbox" ><label for="sk-estimator-id-32" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 88-91

Let's now measure the indicator which tells
if the probability of a prediction is above
a threshold.

.. GENERATED FROM PYTHON SOURCE LINES 91-94

.. code-block:: default


    print(model.validate(X_test))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1
     1]




.. GENERATED FROM PYTHON SOURCE LINES 95-101

Conversion to ONNX
+++++++++++++++++++

The conversion fails for a new model because
the library does not know any converter associated
to this new model.

.. GENERATED FROM PYTHON SOURCE LINES 101-108

.. code-block:: default


    try:
        to_onnx(model, X_train[:1].astype(np.float32),
                target_opset=12)
    except RuntimeError as e:
        print(e)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Unable to find a shape calculator for type '<class '__main__.ValidatorClassifier'>'.
    It usually means the pipeline being converted contains a
    transformer or a predictor with no corresponding converter
    implemented in sklearn-onnx. If the converted is implemented
    in another library, you need to register
    the converted so that it can be used by sklearn-onnx (function
    update_registered_converter). If the model is not yet covered
    by sklearn-onnx, you may raise an issue to
    https://github.com/onnx/sklearn-onnx/issues
    to get the converter implemented or even contribute to the
    project. If the model is a custom model, a new converter must
    be implemented. Examples can be found in the gallery.





.. GENERATED FROM PYTHON SOURCE LINES 109-115

Custom converter
++++++++++++++++

We reuse some pieces of code from :ref:`l-custom-model`.
The shape calculator defines the shape of every output
of the converted model.

.. GENERATED FROM PYTHON SOURCE LINES 115-132

.. code-block:: default



    def validator_classifier_shape_calculator(operator):

        input0 = operator.inputs[0]  # inputs in ONNX graph
        outputs = operator.outputs  # outputs in ONNX graph
        op = operator.raw_operator  # scikit-learn model (mmust be fitted)
        if len(outputs) != 3:
            raise RuntimeError("3 outputs expected not {}.".format(len(outputs)))

        N = input0.type.shape[0]                    # number of observations
        C = op.estimator_.classes_.shape[0]         # dimension of outputs

        outputs[0].type = Int64TensorType([N])      # label
        outputs[1].type = FloatTensorType([N, C])   # probabilities
        outputs[2].type = Int64TensorType([C])      # validation








.. GENERATED FROM PYTHON SOURCE LINES 133-134

Then the converter.

.. GENERATED FROM PYTHON SOURCE LINES 134-179

.. code-block:: default



    def validator_classifier_converter(scope, operator, container):
        outputs = operator.outputs      # outputs in ONNX graph
        op = operator.raw_operator      # scikit-learn model (mmust be fitted)

        # We reuse existing converter and declare it
        # as a local operator.
        model = op.estimator_
        alias = get_model_alias(type(model))
        val_op = scope.declare_local_operator(alias, model)
        val_op.inputs = operator.inputs

        # We add an intermediate outputs.
        val_label = scope.declare_local_variable('val_label', Int64TensorType())
        val_prob = scope.declare_local_variable('val_prob', FloatTensorType())
        val_op.outputs.append(val_label)
        val_op.outputs.append(val_prob)

        # We adjust the output of the submodel.
        shape_calc = get_shape_calculator(alias)
        shape_calc(val_op)

        # We now handle the validation.
        val_max = scope.get_unique_variable_name('val_max')
        container.add_node('ReduceMax', val_prob.full_name, val_max,
                           name=scope.get_unique_operator_name('ReduceMax'),
                           axes=[1], keepdims=0)

        th_name = scope.get_unique_variable_name('threshold')
        container.add_initializer(
            th_name, onnx_proto.TensorProto.FLOAT, [1], [op.threshold])
        val_bin = scope.get_unique_variable_name('val_bin')
        apply_greater(scope, [val_max, th_name], val_bin, container)

        val_val = scope.get_unique_variable_name('validate')
        apply_cast(scope, val_bin, val_val, container,
                   to=onnx_proto.TensorProto.INT64)

        # We finally link the intermediate output to the shared converter.
        apply_identity(scope, val_label.full_name, outputs[0].full_name, container)
        apply_identity(scope, val_prob.full_name, outputs[1].full_name, container)
        apply_identity(scope, val_val, outputs[2].full_name, container)









.. GENERATED FROM PYTHON SOURCE LINES 180-181

Then the registration.

.. GENERATED FROM PYTHON SOURCE LINES 181-187

.. code-block:: default



    update_registered_converter(ValidatorClassifier, 'CustomValidatorClassifier',
                                validator_classifier_shape_calculator,
                                validator_classifier_converter)








.. GENERATED FROM PYTHON SOURCE LINES 188-189

And conversion...

.. GENERATED FROM PYTHON SOURCE LINES 189-196

.. code-block:: default


    try:
        to_onnx(model, X_test[:1].astype(np.float32),
                target_opset=12)
    except RuntimeError as e:
        print(e)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    3 outputs expected not 2.




.. GENERATED FROM PYTHON SOURCE LINES 197-204

It fails because the library expected the model
to behave like a classifier which produces two
outputs. We need to add a custom parser to
tell the library this model produces three outputs.

Custom parser
+++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 204-224

.. code-block:: default



    def validator_classifier_parser(scope, model, inputs, custom_parsers=None):
        alias = get_model_alias(type(model))
        this_operator = scope.declare_local_operator(alias, model)

        # inputs
        this_operator.inputs.append(inputs[0])

        # outputs
        val_label = scope.declare_local_variable('val_label', Int64TensorType())
        val_prob = scope.declare_local_variable('val_prob', FloatTensorType())
        val_val = scope.declare_local_variable('val_val', Int64TensorType())
        this_operator.outputs.append(val_label)
        this_operator.outputs.append(val_prob)
        this_operator.outputs.append(val_val)

        # end
        return this_operator.outputs








.. GENERATED FROM PYTHON SOURCE LINES 225-226

Registration.

.. GENERATED FROM PYTHON SOURCE LINES 226-233

.. code-block:: default



    update_registered_converter(ValidatorClassifier, 'CustomValidatorClassifier',
                                validator_classifier_shape_calculator,
                                validator_classifier_converter,
                                parser=validator_classifier_parser)








.. GENERATED FROM PYTHON SOURCE LINES 234-235

And conversion again.

.. GENERATED FROM PYTHON SOURCE LINES 235-239

.. code-block:: default


    model_onnx = to_onnx(model, X_test[:1].astype(np.float32),
                         target_opset=12)








.. GENERATED FROM PYTHON SOURCE LINES 240-244

Final test
++++++++++

We need now to check the results are the same with ONNX.

.. GENERATED FROM PYTHON SOURCE LINES 244-260

.. code-block:: default


    X32 = X_test[:5].astype(np.float32)

    sess = rt.InferenceSession(model_onnx.SerializeToString())
    results = sess.run(None, {'X': X32})

    print("--labels--")
    print("sklearn", model.predict(X32))
    print("onnx", results[0])
    print("--probabilities--")
    print("sklearn", model.predict_proba(X32))
    print("onnx", results[1])
    print("--validation--")
    print("sklearn", model.validate(X32))
    print("onnx", results[2])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    --labels--
    sklearn [2 0 2 2 1]
    onnx [2 0 2 2 1]
    --probabilities--
    sklearn [[3.71357231e-04 2.96586450e-01 7.03042193e-01]
     [8.65065673e-01 1.34848325e-01 8.60018083e-05]
     [1.17898120e-03 3.65979433e-01 6.32841586e-01]
     [6.79752603e-03 3.68582685e-01 6.24619789e-01]
     [5.02545438e-02 7.88441754e-01 1.61303702e-01]]
    onnx [[3.7135908e-04 2.9658648e-01 7.0304215e-01]
     [8.6506563e-01 1.3484833e-01 8.5985652e-05]
     [1.1789729e-03 3.6597937e-01 6.3284159e-01]
     [6.7974939e-03 3.6858279e-01 6.2461972e-01]
     [5.0254531e-02 7.8844190e-01 1.6130358e-01]]
    --validation--
    sklearn [0 1 0 0 1]
    onnx [0 1 0 0 1]




.. GENERATED FROM PYTHON SOURCE LINES 261-265

It looks good.

Display the ONNX graph
++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 265-279

.. code-block:: default


    pydot_graph = GetPydotGraph(
        model_onnx.graph, name=model_onnx.graph.name, rankdir="TB",
        node_producer=GetOpNodeProducer(
            "docstring", color="yellow", fillcolor="yellow", style="filled"))
    pydot_graph.write_dot("validator_classifier.dot")

    os.system('dot -O -Gdpi=300 -Tpng validator_classifier.dot')

    image = plt.imread("validator_classifier.dot.png")
    fig, ax = plt.subplots(figsize=(40, 20))
    ax.imshow(image)
    ax.axis('off')




.. image-sg:: /auto_examples/images/sphx_glr_plot_custom_parser_001.png
   :alt: plot custom parser
   :srcset: /auto_examples/images/sphx_glr_plot_custom_parser_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    (-0.5, 2513.5, 4934.5, -0.5)



.. GENERATED FROM PYTHON SOURCE LINES 280-281

**Versions used for this example**

.. GENERATED FROM PYTHON SOURCE LINES 281-287

.. code-block:: default


    print("numpy:", np.__version__)
    print("scikit-learn:", sklearn.__version__)
    print("onnx: ", onnx.__version__)
    print("onnxruntime: ", rt.__version__)
    print("skl2onnx: ", skl2onnx.__version__)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    numpy: 1.21.3
    scikit-learn: 1.1.1
    onnx:  1.12.0
    onnxruntime:  1.10.0
    skl2onnx:  1.11.2





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  2.021 seconds)


.. _sphx_glr_download_auto_examples_plot_custom_parser.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/onnx/onnx.ai/sklearn-onnx//master?filepath=auto_examples/auto_examples/plot_custom_parser.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_custom_parser.py <plot_custom_parser.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_custom_parser.ipynb <plot_custom_parser.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
