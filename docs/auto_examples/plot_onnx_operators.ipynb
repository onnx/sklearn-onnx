{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Play with ONNX operators\n\nONNX aims at describing most of the machine learning models\nimplemented in *scikit-learn* but it does not necessarily describe\nthe prediction function the same way *scikit-learn* does.\nIf it is possible to define custom operators, it usually\nrequires some time to add it to ONNX specifications and then to\nthe backend used to compute the predictions. It is better to look\nfirst if the existing operators can be used. The list is available\non *github* and gives the `basic operators\n<https://github.com/onnx/onnx/blob/master/docs/Operators.md>`_\nand others `dedicated to machine learning\n<https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md>`_.\n*ONNX* has a Python API which can be used to define an *ONNX*\ngraph: `PythonAPIOverview.md\n<https://github.com/onnx/onnx/blob/master/docs/PythonAPIOverview.md>`_.\nBut it is quite verbose and makes it difficult to describe big graphs.\n*sklearn-onnx* implements a nicer way to test *ONNX* operators.\n\n## ONNX Python API\n\nLet's try the example given by ONNX documentation:\n`ONNX Model Using Helper Functions\n<https://github.com/onnx/onnx/blob/master/docs/PythonAPIOverview.md\n#creating-an-onnx-model-using-helper-functions>`_.\nIt relies on *protobuf* whose definition can be found\non github `onnx.proto\n<https://github.com/onnx/onnx/blob/master/onnx/onnx.proto>`_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import onnxruntime\nimport numpy\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport onnx\nfrom onnx import helper\nfrom onnx import TensorProto\nfrom onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\n\n# Create one input (ValueInfoProto)\nX = helper.make_tensor_value_info('X', TensorProto.FLOAT, [None, 2])\n\n# Create one output (ValueInfoProto)\nY = helper.make_tensor_value_info('Y', TensorProto.FLOAT, [None, 4])\n\n# Create a node (NodeProto)\nnode_def = helper.make_node(\n    'Pad',  # node name\n    ['X'],  # inputs\n    ['Y'],  # outputs\n    mode='constant',  # attributes\n    value=1.5,\n    pads=[0, 1, 0, 1],\n)\n\n# Create the graph (GraphProto)\ngraph_def = helper.make_graph(\n    [node_def],\n    'test-model',\n    [X],\n    [Y],\n)\n\n# Create the model (ModelProto)\nmodel_def = helper.make_model(graph_def, producer_name='onnx-example')\nmodel_def.opset_import[0].version = 10\n\nprint('The model is:\\n{}'.format(model_def))\nonnx.checker.check_model(model_def)\nprint('The model is checked!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Same example with sklearn-onnx\n\nEvery operator has its own class in *sklearn-onnx*.\nThe list is dynamically created based on the installed\nonnx package.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx.algebra.onnx_ops import OnnxPad  # noqa\n\npad = OnnxPad('X', output_names=['Y'], mode='constant', value=1.5,\n              pads=[0, 1, 0, 1], op_version=10)\nmodel_def = pad.to_onnx({'X': X}, target_opset=10)\n\nprint('The model is:\\n{}'.format(model_def))\nonnx.checker.check_model(model_def)\nprint('The model is checked!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inputs and outputs can also be skipped.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pad = OnnxPad(mode='constant', value=1.5,\n              pads=[0, 1, 0, 1], op_version=10)\n\nmodel_def = pad.to_onnx({pad.inputs[0].name: X}, target_opset=10)\nonnx.checker.check_model(model_def)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multiple operators\n\nLet's use the second example from the documentation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Preprocessing: create a model with two nodes, Y's shape is unknown\nnode1 = helper.make_node('Transpose', ['X'], ['Y'], perm=[1, 0, 2])\nnode2 = helper.make_node('Transpose', ['Y'], ['Z'], perm=[1, 0, 2])\n\ngraph = helper.make_graph(\n    [node1, node2],\n    'two-transposes',\n    [helper.make_tensor_value_info('X', TensorProto.FLOAT, (2, 3, 4))],\n    [helper.make_tensor_value_info('Z', TensorProto.FLOAT, (2, 3, 4))],\n)\n\noriginal_model = helper.make_model(graph, producer_name='onnx-examples')\n\n# Check the model and print Y's shape information\nonnx.checker.check_model(original_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Which we translate into:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skl2onnx.algebra.onnx_ops import OnnxTranspose  # noqa\n\nnode = OnnxTranspose(\n    OnnxTranspose('X', perm=[1, 0, 2], op_version=12),\n    perm=[1, 0, 2], op_version=12)\nX = np.arange(2 * 3 * 4).reshape((2, 3, 4)).astype(np.float32)\n\n# numpy arrays are good enough to define the input shape\nmodel_def = node.to_onnx({'X': X}, target_opset=12)\nonnx.checker.check_model(model_def)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's the output with onnxruntime\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def predict_with_onnxruntime(model_def, *inputs):\n    import onnxruntime as ort\n    sess = ort.InferenceSession(model_def.SerializeToString())\n    names = [i.name for i in sess.get_inputs()]\n    dinputs = {name: input for name, input in zip(names, inputs)}\n    res = sess.run(None, dinputs)\n    names = [o.name for o in sess.get_outputs()]\n    return {name: output for name, output in zip(names, res)}\n\n\nY = predict_with_onnxruntime(model_def, X)\nprint(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display the ONNX graph\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pydot_graph = GetPydotGraph(\n    model_def.graph, name=model_def.graph.name, rankdir=\"TB\",\n    node_producer=GetOpNodeProducer(\"docstring\", color=\"yellow\",\n                                    fillcolor=\"yellow\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline_transpose2x.dot\")\n\nos.system('dot -O -Gdpi=300 -Tpng pipeline_transpose2x.dot')\n\nimage = plt.imread(\"pipeline_transpose2x.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sklearn  # noqa\nprint(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nimport skl2onnx  # noqa\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", onnxruntime.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}