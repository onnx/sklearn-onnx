{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Write your own converter for your own model\n\nIt might happen that you implemented your own model\nand there is obviously no existing converter for this\nnew model. That does not mean the conversion of a pipeline\nwhich includes it would not work. Let's see how to do it.\n\n`t-SNE <https://lvdmaaten.github.io/tsne/>`_ is an interesting\ntransform which can only be used to study data as there is no\nway to reproduce the result once it was fitted. That's why\nthe class `TSNE <https://scikit-learn.org/stable/modules/\ngenerated/sklearn.manifold.TSNE.html>`_\ndoes not have any method *transform*, only\n`fit_transform <https://scikit-learn.org/stable/modules/\ngenerated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE.fit_transform>`_.\nThis example proposes a way to train a machine learned model\nwhich approximates the outputs of a *t-SNE* transformer.\n\n## Implementation of the new transform\n\nThe first section is about the implementation.\nThe code is quite generic but basically follows this\nprocess to fit the model with *X* and *y*:\n\n* t-SNE, $(X, y) \\rightarrow X_2 \\in \\mathbb{R}^2$\n* k nearest neightbours, $fit(X, X_2)$,\n  which produces function $f(X) \\rightarrow X_3$\n* final normalization, simple scaling $X_3 \\rightarrow X_4$\n\nAnd to predict on a test set:\n\n* k nearest neightbours, $f(X') \\rightarrow X'_3$\n* final normalization, simple scaling $X'_3 \\rightarrow X'_4$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import inspect\nimport os\nimport numpy\nimport onnx\nfrom onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\nimport onnxruntime as rt\nfrom matplotlib import offsetbox\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\nfrom sklearn.base import BaseEstimator, TransformerMixin, clone\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom skl2onnx import update_registered_converter\nimport skl2onnx\nfrom skl2onnx import convert_sklearn, get_model_alias\nfrom skl2onnx.common._registration import get_shape_calculator\nfrom skl2onnx.common.data_types import FloatTensorType\n\n\nclass PredictableTSNE(BaseEstimator, TransformerMixin):\n\n    def __init__(self, transformer=None, estimator=None,\n                 normalize=True, keep_tsne_outputs=False, **kwargs):\n        \"\"\"\n        :param transformer: `TSNE` by default\n        :param estimator: `MLPRegressor` by default\n        :param normalize: normalizes the outputs, centers and normalizes\n            the output of the *t-SNE* and applies that same\n            normalization to he prediction of the estimator\n        :param keep_tsne_output: if True, keep raw outputs of\n            *TSNE* is stored in member *tsne_outputs_*\n        :param kwargs: sent to :meth:`set_params <mlinsights.mlmodel.\n            tsne_transformer.PredictableTSNE.set_params>`, see its\n            documentation to understand how to specify parameters\n        \"\"\"\n        TransformerMixin.__init__(self)\n        BaseEstimator.__init__(self)\n        if estimator is None:\n            estimator = KNeighborsRegressor()\n        if transformer is None:\n            transformer = TSNE()\n        self.estimator = estimator\n        self.transformer = transformer\n        self.keep_tsne_outputs = keep_tsne_outputs\n        if not hasattr(transformer, \"fit_transform\"):\n            raise AttributeError(\n                \"Transformer {} does not have a 'fit_transform' \"\n                \"method.\".format(type(transformer)))\n        if not hasattr(estimator, \"predict\"):\n            raise AttributeError(\n                \"Estimator {} does not have a 'predict' method.\".format(\n                    type(estimator)))\n        self.normalize = normalize\n        if kwargs:\n            self.set_params(**kwargs)\n\n    def fit(self, X, y, sample_weight=None):\n        \"\"\"\n        Runs a *k-means* on each class\n        then trains a classifier on the\n        extended set of features.\n        Parameters\n        ----------\n        X : numpy array or sparse matrix of shape [n_samples,n_features]\n            Training data\n        y : numpy array of shape [n_samples, n_targets]\n            Target values. Will be cast to X's dtype if necessary\n        sample_weight : numpy array of shape [n_samples]\n            Individual weights for each sample\n        Returns\n        -------\n        self : returns an instance of self.\n        Attributes\n        ----------\n        transformer_: trained transformeer\n        estimator_: trained regressor\n        tsne_outputs_: t-SNE outputs if *keep_tsne_outputs* is True\n        mean_: average of the *t-SNE* output on each dimension\n        inv_std_: inverse of the standard deviation of the *t-SNE*\n            output on each dimension\n        loss_: loss (*mean_squared_error*)\n        between the predictions and the outputs of t-SNE\n        \"\"\"\n        params = dict(y=y, sample_weight=sample_weight)\n\n        self.transformer_ = clone(self.transformer)\n\n        sig = inspect.signature(self.transformer.fit_transform)\n        pars = {}\n        for p in ['sample_weight', 'y']:\n            if p in sig.parameters and p in params:\n                pars[p] = params[p]\n        target = self.transformer_.fit_transform(X, **pars)\n\n        sig = inspect.signature(self.estimator.fit)\n        if 'sample_weight' in sig.parameters:\n            self.estimator_ = clone(self.estimator).fit(\n                X, target, sample_weight=sample_weight)\n        else:\n            self.estimator_ = clone(self.estimator).fit(X, target)\n        mean = target.mean(axis=0)\n        var = target.std(axis=0)\n        self.mean_ = mean\n        self.inv_std_ = 1. / var\n        exp = (target - mean) * self.inv_std_\n        got = (self.estimator_.predict(X) - mean) * self.inv_std_\n        self.loss_ = mean_squared_error(exp, got)\n        if self.keep_tsne_outputs:\n            self.tsne_outputs_ = exp if self.normalize else target\n        return self\n\n    def transform(self, X):\n        \"\"\"\n        Runs the predictions.\n        Parameters\n        ----------\n        X : numpy array or sparse matrix of shape [n_samples,n_features]\n            Training data\n        Returns\n        -------\n        tranformed *X*\n        \"\"\"\n        pred = self.estimator_.predict(X)\n        if self.normalize:\n            pred -= self.mean_\n            pred *= self.inv_std_\n        return pred\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Returns the parameters for all the embedded objects.\n        \"\"\"\n        res = {}\n        for k, v in self.transformer.get_params().items():\n            res[\"t_\" + k] = v\n        for k, v in self.estimator.get_params().items():\n            res[\"e_\" + k] = v\n        return res\n\n    def set_params(self, **values):\n        \"\"\"\n        Sets the parameters before training.\n        Every parameter prefixed by ``'e_'`` is an estimator\n        parameter, every parameter prefixed by\n        ``t_`` is for a transformer parameter.\n        \"\"\"\n        pt, pe, pn = {}, {}, {}\n        for k, v in values.items():\n            if k.startswith('e_'):\n                pe[k[2:]] = v\n            elif k.startswith('t_'):\n                pt[k[2:]] = v\n            elif k.startswith('n_'):\n                pn[k[2:]] = v\n            else:\n                raise ValueError(\"Unexpected parameter name '{0}'.\".format(k))\n        self.transformer.set_params(**pt)\n        self.estimator.set_params(**pe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimentation on MNIST\n\nLet's fit t-SNE...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "digits = datasets.load_digits(n_class=6)\nXd = digits.data\nyd = digits.target\nimgs = digits.images\nn_samples, n_features = Xd.shape\nn_samples, n_features\n\nX_train, X_test, y_train, y_test, imgs_train, imgs_test = train_test_split(\n    Xd, yd, imgs)\n\ntsne = TSNE(n_components=2, init='pca', random_state=0)\n\n\ndef plot_embedding(Xp, y, imgs, title=None, figsize=(12, 4)):\n    x_min, x_max = numpy.min(Xp, 0), numpy.max(Xp, 0)\n    X = (Xp - x_min) / (x_max - x_min)\n\n    fig, ax = plt.subplots(1, 2, figsize=figsize)\n    for i in range(X.shape[0]):\n        ax[0].text(X[i, 0], X[i, 1], str(y[i]),\n                   color=plt.cm.Set1(y[i] / 10.),\n                   fontdict={'weight': 'bold', 'size': 9})\n\n    if hasattr(offsetbox, 'AnnotationBbox'):\n        # only print thumbnails with matplotlib > 1.0\n        shown_images = numpy.array([[1., 1.]])  # just something big\n        for i in range(X.shape[0]):\n            dist = numpy.sum((X[i] - shown_images) ** 2, 1)\n            if numpy.min(dist) < 4e-3:\n                # don't show points that are too close\n                continue\n            shown_images = numpy.r_[shown_images, [X[i]]]\n            imagebox = offsetbox.AnnotationBbox(\n                offsetbox.OffsetImage(imgs[i], cmap=plt.cm.gray_r),\n                X[i])\n            ax[0].add_artist(imagebox)\n    ax[0].set_xticks([]), ax[0].set_yticks([])\n    ax[1].plot(Xp[:, 0], Xp[:, 1], '.')\n    if title is not None:\n        ax[0].set_title(title)\n    return ax\n\n\nX_train_tsne = tsne.fit_transform(X_train)\nplot_embedding(X_train_tsne, y_train, imgs_train,\n               \"t-SNE embedding of the digits\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Repeatable t-SNE\n\nJust to check it is working.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ptsne_knn = PredictableTSNE()\nptsne_knn.fit(X_train, y_train)\n\nX_train_tsne2 = ptsne_knn.transform(X_train)\nplot_embedding(X_train_tsne2, y_train, imgs_train,\n               \"Predictable t-SNE of the digits\\n\"\n               \"StandardScaler+KNeighborsRegressor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check on test set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_test_tsne2 = ptsne_knn.transform(X_test)\nplot_embedding(X_test_tsne2, y_test, imgs_test,\n               \"Predictable t-SNE of the digits\\n\"\n               \"StandardScaler+KNeighborsRegressor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ONNX - shape_calculator, converter\n\nNow starts the part dedicated to *ONNX*.\n*ONNX* conversion requires two function,\none to calculate the shape of the outputs based\non the inputs, the other one to do the actual\nconversion of the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def predictable_tsne_shape_calculator(operator):\n\n    input = operator.inputs[0]      # inputs in ONNX graph\n    # output = operator.outputs[0]    # output in ONNX graph\n    op = operator.raw_operator      # scikit-learn model (mmust be fitted)\n\n    N = input.type.shape[0]         # number of observations\n    C = op.estimator_._y.shape[1]   # dimension of outputs\n\n    # new output definition\n    operator.outputs[0].type = FloatTensorType([N, C])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then the converter model. We\nreuse existing converter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def predictable_tsne_converter(scope, operator, container):\n    \"\"\"\n    :param scope: name space, where to keep node names, get unused new names\n    :param operator: operator to converter, same object as sent to\n        *predictable_tsne_shape_calculator*\n    :param container: contains the ONNX graph\n    \"\"\"\n    # input = operator.inputs[0]      # input in ONNX graph\n    output = operator.outputs[0]    # output in ONNX graph\n    op = operator.raw_operator      # scikit-learn model (mmust be fitted)\n\n    # First step is the k nearest-neighbours,\n    # we reuse existing converter and declare it as local\n    # operator.\n    model = op.estimator_\n    alias = get_model_alias(type(model))\n    knn_op = scope.declare_local_operator(alias, model)\n    knn_op.inputs = operator.inputs\n\n    # We add an intermediate outputs.\n    knn_output = scope.declare_local_variable('knn_output', FloatTensorType())\n    knn_op.outputs.append(knn_output)\n\n    # We adjust the output of the submodel.\n    shape_calc = get_shape_calculator(alias)\n    shape_calc(knn_op)\n\n    # We add the normalizer which needs a unique node name.\n    name = scope.get_unique_operator_name('Scaler')\n\n    # The parameter follows the specifications of ONNX\n    # https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md#ai.onnx.ml.Scaler\n    attrs = dict(name=name,\n                 scale=op.inv_std_.ravel().astype(numpy.float32),\n                 offset=op.mean_.ravel().astype(numpy.float32))\n\n    # Let's finally add the scaler which connects the output\n    # of the k-nearest neighbours model to output of the whole model\n    # declared in ONNX graph\n    container.add_node('Scaler', [knn_output.onnx_name], [output.full_name],\n                       op_domain='ai.onnx.ml', **attrs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now need to declare the new converter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "update_registered_converter(PredictableTSNE, 'CustomPredictableTSNE',\n                            predictable_tsne_shape_calculator,\n                            predictable_tsne_converter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion to ONNX\n\nWe just need to call *convert_sklearn* as any other model\nto convert.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_onnx = convert_sklearn(\n    ptsne_knn, 'predictable_tsne',\n    [('input', FloatTensorType([None, X_test.shape[1]]))],\n    target_opset=12)\n\n# And save.\nwith open(\"predictable_tsne.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now compare the prediction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"ptsne_knn.tranform\\n\", ptsne_knn.transform(X_test[:2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictions with onnxruntime.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = rt.InferenceSession(\"predictable_tsne.onnx\")\n\npred_onx = sess.run(None, {\"input\": X_test[:1].astype(numpy.float32)})\nprint(\"transform\", pred_onx[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The converter for the nearest neighbours produces an ONNX graph\nwhich does not allow multiple predictions at a time. Let's call\n*onnxruntime* for the second row.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_onx = sess.run(None, {\"input\": X_test[1:2].astype(numpy.float32)})\nprint(\"transform\", pred_onx[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display the ONNX graph\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pydot_graph = GetPydotGraph(\n    model_onnx.graph, name=model_onnx.graph.name, rankdir=\"TB\",\n    node_producer=GetOpNodeProducer(\n        \"docstring\", color=\"yellow\", fillcolor=\"yellow\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline_tsne.dot\")\n\nos.system('dot -O -Gdpi=300 -Tpng pipeline_tsne.dot')\n\nimage = plt.imread(\"pipeline_tsne.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Versions used for this example**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"numpy:\", numpy.__version__)\nprint(\"scikit-learn:\", sklearn.__version__)\nprint(\"onnx: \", onnx.__version__)\nprint(\"onnxruntime: \", rt.__version__)\nprint(\"skl2onnx: \", skl2onnx.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}