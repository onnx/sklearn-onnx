{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# One model, many possible conversions with options\n\n.. index:: options\n\nThere is not one way to convert a model. A new operator\nmight have been added in a newer version of :epkg:`ONNX`\nand that speeds up the converted model. The rational choice\nwould be to use this new operator but what means the associated\nruntime has an implementation for it. What if two different\nusers needs two different conversion for the same model?\nLet's see how this may be done.\n\n\n## Option *zipmap*\n\nEvery classifier is by design converted into an ONNX graph which outputs\ntwo results: the predicted label and the prediction probabilites\nfor every label. By default, the labels are integers and the\nprobabilites are stored in dictionaries. That's the purpose\nof operator *ZipMap* added at the end of the following graph.\n\n.. gdot::\n    :script: DOT-SECTION\n\n    import numpy\n    from sklearn.datasets import load_iris\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LogisticRegression\n    from skl2onnx import to_onnx\n    from mlprodict.onnxrt import OnnxInference\n\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    X_train, _, y_train, __ = train_test_split(X, y, random_state=11)\n    clr = LogisticRegression()\n    clr.fit(X_train, y_train)\n\n    model_def = to_onnx(clr, X_train.astype(numpy.float32))\n    oinf = OnnxInference(model_def)\n    print(\"DOT-SECTION\", oinf.to_dot())\n\nThis operator is not really efficient as it copies every probabilies and\nlabels in a different container. This time is usually significant for\nsmall classifiers. Then it makes sense to remove it.\n\n.. gdot::\n    :script: DOT-SECTION\n\n    import numpy\n    from sklearn.datasets import load_iris\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LogisticRegression\n    from skl2onnx import to_onnx\n    from mlprodict.onnxrt import OnnxInference\n\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    X_train, _, y_train, __ = train_test_split(X, y, random_state=11)\n    clr = LogisticRegression()\n    clr.fit(X_train, y_train)\n\n    model_def = to_onnx(clr, X_train.astype(numpy.float32),\n                        options={LogisticRegression: {'zipmap': False}})\n    oinf = OnnxInference(model_def)\n    print(\"DOT-SECTION\", oinf.to_dot())\n\nThere might be in the graph many classifiers, it is important to have\na way to specify which classifier should keep its *ZipMap*\nand which is not. So it is possible to specify options by id.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pprint import pformat\nimport numpy\nfrom pyquickhelper.helpgen.graphviz_helper import plot_graphviz\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom skl2onnx.common._registration import _converter_pool\nfrom skl2onnx import to_onnx\nfrom onnxruntime import InferenceSession\nfrom mlprodict.onnxrt import OnnxInference\n\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, _ = train_test_split(X, y, random_state=11)\nclr = LogisticRegression()\nclr.fit(X_train, y_train)\n\nmodel_def = to_onnx(clr, X_train.astype(numpy.float32),\n                    options={id(clr): {'zipmap': False}})\noinf = OnnxInference(model_def, runtime='python_compiled')\nprint(oinf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visually.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to compare that kind of visualisation to\nwhat it would give with operator *ZipMap*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_def = to_onnx(clr, X_train.astype(numpy.float32))\noinf = OnnxInference(model_def, runtime='python_compiled')\nprint(oinf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visually.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using function *id* has one flaw: it is not pickable.\nIt is just better to use strings.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_def = to_onnx(clr, X_train.astype(numpy.float32),\n                    options={'zipmap': False})\noinf = OnnxInference(model_def, runtime='python_compiled')\nprint(oinf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visually.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option in a pipeline\n\nIn a pipeline, :epkg:`sklearn-onnx` uses the same\nname convention.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline([\n    ('norm', MinMaxScaler()),\n    ('clr', LogisticRegression())\n])\npipe.fit(X_train, y_train)\n\nmodel_def = to_onnx(pipe, X_train.astype(numpy.float32),\n                    options={'clr__zipmap': False})\noinf = OnnxInference(model_def, runtime='python_compiled')\nprint(oinf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visually.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option *raw_scores*\n\nEvery classifier is converted in a graph which\nreturns probabilities by default. But many models\ncompute unscaled *raw_scores*.\nFirst, with probabilities:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline([\n    ('norm', MinMaxScaler()),\n    ('clr', LogisticRegression())\n])\npipe.fit(X_train, y_train)\n\nmodel_def = to_onnx(\n    pipe, X_train.astype(numpy.float32),\n    options={id(pipe): {'zipmap': False}})\n\noinf = OnnxInference(model_def, runtime='python_compiled')\nprint(oinf.run({'X': X.astype(numpy.float32)[:5]}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then with raw scores:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_def = to_onnx(\n    pipe, X_train.astype(numpy.float32),\n    options={id(pipe): {'raw_scores': True, 'zipmap': False}})\n\noinf = OnnxInference(model_def, runtime='python_compiled')\nprint(oinf.run({'X': X.astype(numpy.float32)[:5]}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It did not seem to work... We need to tell\nthat applies on a specific part of the pipeline\nand not the whole pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_def = to_onnx(\n    pipe, X_train.astype(numpy.float32),\n    options={id(pipe.steps[1][1]): {'raw_scores': True, 'zipmap': False}})\n\noinf = OnnxInference(model_def, runtime='python_compiled')\nprint(oinf.run({'X': X.astype(numpy.float32)[:5]}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are negative values. That works.\nStrings are still easier to use.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_def = to_onnx(\n    pipe, X_train.astype(numpy.float32),\n    options={'clr__raw_scores': True, 'clr__zipmap': False})\n\noinf = OnnxInference(model_def, runtime='python_compiled')\nprint(oinf.run({'X': X.astype(numpy.float32)[:5]}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Negative figures. We still have raw scores.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option *decision_path*\n\n*scikit-learn* implements a function to retrieve the\ndecision path. It can be enabled by option *decision_path*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clrrf = RandomForestClassifier(n_estimators=2, max_depth=2)\nclrrf.fit(X_train, y_train)\nclrrf.predict(X_test[:2])\npaths, n_nodes_ptr = clrrf.decision_path(X_test[:2])\nprint(paths.todense())\n\nmodel_def = to_onnx(clrrf, X_train.astype(numpy.float32),\n                    options={id(clrrf): {'decision_path': True,\n                                         'zipmap': False}})\nsess = InferenceSession(model_def.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model produces 3 outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print([o.name for o in sess.get_outputs()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's display the last one.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "res = sess.run(None, {'X': X_test[:2].astype(numpy.float32)})\nprint(res[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List of available options\n\nOptions are registered for every converted to detect any\nsupported options while running the conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_opts = set()\nfor k, v in sorted(_converter_pool.items()):\n    opts = v.get_allowed_options()\n    if not isinstance(opts, dict):\n        continue\n    name = k.replace('Sklearn', '')\n    print('%s%s %r' % (name, \" \" * (30 - len(name)), opts))\n    for o in opts:\n        all_opts.add(o)\n\nprint('all options:', pformat(list(sorted(all_opts))))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}