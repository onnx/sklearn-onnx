{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Fast design with a python runtime\n\n.. index:: custom python runtime\n\n:epkg:`ONNX operators` do not contain all operators\nfrom :epkg:`numpy`. There is no operator for\n`solve <https://numpy.org/doc/stable/reference/\ngenerated/numpy.linalg.solve.html>`_ but this one\nis needed to implement the prediction function\nof model :epkg:`NMF`. The converter can be written\nincluding a new ONNX operator but then it requires a\nruntime for it to be tested. This example shows how\nto do that with the python runtime implemented in\n:epkg:`mlprodict`. It may not be :epkg:`onnxruntime`\nbut that speeds up the implementation of the converter.\n\nThe example changes the transformer from\n`l-plot-custom-converter`, the method *predict*\ndecorrelates the variables by computing the eigen\nvalues. Method *fit* does not do anything anymore.\n\n## A transformer which decorrelates variables\n\nThis time, the eigen values are not estimated at\ntraining time but at prediction time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mlprodict.onnxrt.shape_object import ShapeObject\nfrom mlprodict.onnxrt.ops_cpu import OpRunCustom, register_operator\nfrom skl2onnx.algebra.onnx_ops import (\n    OnnxAdd,\n    OnnxCast,\n    OnnxDiv,\n    OnnxGatherElements,\n    OnnxEyeLike,\n    OnnxMatMul,\n    OnnxMul,\n    OnnxPow,\n    OnnxReduceMean,\n    OnnxShape,\n    OnnxSub,\n    OnnxTranspose,\n)\nfrom skl2onnx.algebra import OnnxOperator\nfrom mlprodict.onnxrt import OnnxInference\nfrom pyquickhelper.helpgen.graphviz_helper import plot_graphviz\nimport pickle\nfrom io import BytesIO\nimport numpy\nfrom numpy.testing import assert_almost_equal\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.datasets import load_iris\nfrom skl2onnx.common.data_types import guess_numpy_type, guess_proto_type\nfrom skl2onnx import to_onnx\nfrom skl2onnx import update_registered_converter\n\n\nclass LiveDecorrelateTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"\n    Decorrelates correlated gaussian features.\n\n    :param alpha: avoids non inversible matrices\n        by adding *alpha* identity matrix\n\n    *Attributes*\n\n    * `self.nf_`: number of expected features\n    \"\"\"\n\n    def __init__(self, alpha=0.):\n        BaseEstimator.__init__(self)\n        TransformerMixin.__init__(self)\n        self.alpha = alpha\n\n    def fit(self, X, y=None, sample_weights=None):\n        if sample_weights is not None:\n            raise NotImplementedError(\n                \"sample_weights != None is not implemented.\")\n        self.nf_ = X.shape[1]\n        return self\n\n    def transform(self, X):\n        mean_ = numpy.mean(X, axis=0, keepdims=True)\n        X2 = X - mean_\n        V = X2.T @ X2 / X2.shape[0]\n        if self.alpha != 0:\n            V += numpy.identity(V.shape[0]) * self.alpha\n        L, P = numpy.linalg.eig(V)\n        Linv = L ** (-0.5)\n        diag = numpy.diag(Linv)\n        root = P @ diag @ P.transpose()\n        coef_ = root\n        return (X - mean_) @ coef_\n\n\ndef test_live_decorrelate_transformer():\n    data = load_iris()\n    X = data.data\n\n    dec = LiveDecorrelateTransformer()\n    dec.fit(X)\n    pred = dec.transform(X)\n    cov = pred.T @ pred\n    cov /= cov[0, 0]\n    assert_almost_equal(numpy.identity(4), cov)\n\n    dec = LiveDecorrelateTransformer(alpha=1e-10)\n    dec.fit(X)\n    pred = dec.transform(X)\n    cov = pred.T @ pred\n    cov /= cov[0, 0]\n    assert_almost_equal(numpy.identity(4), cov)\n\n    st = BytesIO()\n    pickle.dump(dec, st)\n    dec2 = pickle.load(BytesIO(st.getvalue()))\n    assert_almost_equal(dec.transform(X), dec2.transform(X))\n\n\ntest_live_decorrelate_transformer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Everything works as expected.\n\n## Extend ONNX\n\nThe conversion requires one operator to compute\nthe eigen values and vectors. The list of\n:epkg:`ONNX operators` does not contain anything\nwhich produces eigen values. It does not seem\nefficient to implement an algorithm with existing\nONNX operators to find eigen values.\nA new operator must be\nadded, we give it the same name *Eig* as in :epkg:`numpy`.\nIt would take a matrix and would produce one or two outputs,\nthe eigen values and the eigen vectors.\nJust for the exercise, a parameter specifies\nto output the eigen vectors as a second output.\n\n### New ONNX operator\n\nAny unknown operator can be\nadded to an ONNX graph. Operators are grouped by domain,\n`''` or `ai.onnx` refers to matrix computation.\n`ai.onnx.ml` refers to usual machine learning models.\nNew domains are officially supported by :epkg:`onnx` package.\nWe want to create a new operator `Eig` of domain `onnxcustom`.\nIt must be declared in a class, then a converter can use it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class OnnxEig(OnnxOperator):\n    \"\"\"\n    Defines a custom operator not defined by ONNX\n    specifications but in onnxruntime.\n    \"\"\"\n\n    since_version = 1  # last changed in this version\n    expected_inputs = [('X', 'T')]  # input names and types\n    expected_outputs = [('EigenValues', 'T'),  # output names and types\n                        ('EigenVectors', 'T')]\n    input_range = [1, 1]  # only one input is allowed\n    output_range = [1, 2]  # 1 or 2 outputs are produced\n    is_deprecated = False  # obviously not deprecated\n    domain = 'onnxcustom'  # domain, anything is ok\n    operator_name = 'Eig'  # operator name\n    past_version = {}  # empty as it is the first version\n\n    def __init__(self, X, eigv=False, op_version=None, **kwargs):\n        \"\"\"\n        :param X: array or OnnxOperatorMixin\n        :param eigv: also produces the eigen vectors\n        :param op_version: opset version\n        :param kwargs: additional parameters\n        \"\"\"\n        OnnxOperator.__init__(\n            self, X, eigv=eigv, op_version=op_version, **kwargs)\n\n\nprint(OnnxEig('X', eigv=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can write the converter and\nthe shape calculator.\n\n### shape calculator\n\nNothing new here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def live_decorrelate_transformer_shape_calculator(operator):\n    op = operator.raw_operator\n    input_type = operator.inputs[0].type.__class__\n    input_dim = operator.inputs[0].type.shape[0]\n    output_type = input_type([input_dim, op.nf_])\n    operator.outputs[0].type = output_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### converter\n\nThe converter is using the class `OnnxEig`. The code\nis longer than previous converters as the computation is\nmore complex too.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def live_decorrelate_transformer_converter(scope, operator, container):\n    # shortcuts\n    op = operator.raw_operator\n    opv = container.target_opset\n    out = operator.outputs\n\n    # We retrieve the unique input.\n    X = operator.inputs[0]\n\n    # We guess its type. If the operator ingests float (or double),\n    # it outputs float (or double).\n    proto_dtype = guess_proto_type(X.type)\n    dtype = guess_numpy_type(X.type)\n\n    # Lines in comment specify the numpy computation\n    # the ONNX code implements.\n    # mean_ = numpy.mean(X, axis=0, keepdims=True)\n    mean = OnnxReduceMean(X, axes=[0], keepdims=1, op_version=opv)\n\n    # This is trick I often use. The converter automatically\n    # chooses a name for every output. In big graph,\n    # it is difficult to know which operator is producing which output.\n    # This line just tells every node must prefix its ouputs with this string.\n    # It also applies to all inputs nodes unless this method\n    # was called for one of these nodes.\n    mean.set_onnx_name_prefix('mean')\n\n    # X2 = X - mean_\n    X2 = OnnxSub(X, mean, op_version=opv)\n\n    # V = X2.T @ X2 / X2.shape[0]\n    N = OnnxGatherElements(\n        OnnxShape(X, op_version=opv),\n        numpy.array([0], dtype=numpy.int64),\n        op_version=opv)\n    Nf = OnnxCast(N, to=proto_dtype, op_version=opv)\n\n    # Every output involved in N and Nf is prefixed by 'N'.\n    Nf.set_onnx_name_prefix('N')\n\n    V = OnnxDiv(\n        OnnxMatMul(OnnxTranspose(X2, op_version=opv),\n                   X2, op_version=opv),\n        Nf, op_version=opv)\n    V.set_onnx_name_prefix('V1')\n\n    # V += numpy.identity(V.shape[0]) * self.alpha\n    V = OnnxAdd(V,\n                op.alpha * numpy.identity(op.nf_, dtype=dtype),\n                op_version=opv)\n    V.set_onnx_name_prefix('V2')\n\n    # L, P = numpy.linalg.eig(V)\n    LP = OnnxEig(V, eigv=True, op_version=opv)\n    LP.set_onnx_name_prefix('LP')\n\n    # Linv = L ** (-0.5)\n    # Notation LP[0] means OnnxPow is taking the first output\n    # of operator OnnxEig, LP[1] would mean the second one\n    # LP is not allowed as it is ambiguous\n    Linv = OnnxPow(LP[0], numpy.array([-0.5], dtype=dtype),\n                   op_version=opv)\n    Linv.set_onnx_name_prefix('Linv')\n\n    # diag = numpy.diag(Linv)\n    diag = OnnxMul(\n        OnnxEyeLike(\n            numpy.array([op.nf_, op.nf_], dtype=numpy.int64),\n            k=0, op_version=opv),\n        Linv, op_version=opv)\n    diag.set_onnx_name_prefix('diag')\n\n    # root = P @ diag @ P.transpose()\n    trv = OnnxTranspose(LP[1], op_version=opv)\n    coef_left = OnnxMatMul(LP[1], diag, op_version=opv)\n    coef_left.set_onnx_name_prefix('coef_left')\n    coef = OnnxMatMul(coef_left, trv, op_version=opv)\n    coef.set_onnx_name_prefix('coef')\n\n    # Same part as before.\n    Y = OnnxMatMul(X2, coef, op_version=opv, output_names=out[:1])\n    Y.set_onnx_name_prefix('Y')\n\n    # The last line specifies the final output.\n    # Every node involved in the computation is added to the ONNX\n    # graph at this stage.\n    Y.add_to(scope, container)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Runtime for Eig\n\nHere comes the new part. The python runtime does not\nimplement any runtime for *Eig*. We need to tell the runtime\nto compute eigen values and vectors every time operator *Eig*\nis called. That means implementing two methods,\none to compute, one to infer the shape of the results.\nThe first one is mandatory, the second one can return an\nempty shape if it depends on the inputs. If it is known,\nthe runtime may be able to optimize the computation,\nby reducing allocation for example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class OpEig(OpRunCustom):\n\n    op_name = 'Eig'  # operator name\n    atts = {'eigv': True}  # operator parameters\n\n    def __init__(self, onnx_node, desc=None, **options):\n        # constructor, every parameter is added a member\n        OpRunCustom.__init__(self, onnx_node, desc=desc,\n                             expected_attributes=OpEig.atts,\n                             **options)\n\n    def run(self, x):\n        # computation\n        if self.eigv:\n            return numpy.linalg.eig(x)\n        return (numpy.linalg.eigvals(x), )\n\n    def infer_shapes(self, x):\n        # shape inference, if you don't know what to\n        # write, just return `ShapeObject(None)`\n        if self.eigv:\n            return (\n                ShapeObject(\n                    x.shape, dtype=x.dtype,\n                    name=self.__class__.__name__ + 'Values'),\n                ShapeObject(\n                    x.shape, dtype=x.dtype,\n                    name=self.__class__.__name__ + 'Vectors'))\n        return (ShapeObject(x.shape, dtype=x.dtype,\n                            name=self.__class__.__name__), )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Registration\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "update_registered_converter(\n    LiveDecorrelateTransformer, \"SklearnLiveDecorrelateTransformer\",\n    live_decorrelate_transformer_shape_calculator,\n    live_decorrelate_transformer_converter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = load_iris()\nX = data.data\n\ndec = LiveDecorrelateTransformer()\ndec.fit(X)\n\nonx = to_onnx(dec, X.astype(numpy.float32))\n\nregister_operator(OpEig, name='Eig', overwrite=False)\n\noinf = OnnxInference(onx)\n\nexp = dec.transform(X.astype(numpy.float32))\ngot = oinf.run({'X': X.astype(numpy.float32)})['variable']\n\n\ndef diff(p1, p2):\n    p1 = p1.ravel()\n    p2 = p2.ravel()\n    d = numpy.abs(p2 - p1)\n    return d.max(), (d / numpy.abs(p1)).max()\n\n\nprint(diff(exp, got))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It works!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final graph\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "oinf = OnnxInference(onx)\nax = plot_graphviz(oinf.to_dot())\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}