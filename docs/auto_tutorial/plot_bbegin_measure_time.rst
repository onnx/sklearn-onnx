
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorial\plot_bbegin_measure_time.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_tutorial_plot_bbegin_measure_time.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorial_plot_bbegin_measure_time.py:


Benchmark ONNX conversion
=========================

.. index:: benchmark

Example :ref:`l-simple-deploy-1` converts a simple model.
This example takes a similar example but on random data
and compares the processing time required by each option
to compute predictions.

.. contents::
    :local:


Training a pipeline
+++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 21-50

.. code-block:: default

    import numpy
    from pandas import DataFrame
    from tqdm import tqdm
    from sklearn import config_context
    from sklearn.datasets import make_regression
    from sklearn.ensemble import (
        GradientBoostingRegressor, RandomForestRegressor,
        VotingRegressor)
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import train_test_split
    from mlprodict.onnxrt import OnnxInference
    from onnxruntime import InferenceSession
    from skl2onnx import to_onnx
    from skl2onnx.tutorial import measure_time


    N = 11000
    X, y = make_regression(N, n_features=10)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, train_size=0.01)
    print("Train shape", X_train.shape)
    print("Test shape", X_test.shape)

    reg1 = GradientBoostingRegressor(random_state=1)
    reg2 = RandomForestRegressor(random_state=1)
    reg3 = LinearRegression()
    ereg = VotingRegressor([('gb', reg1), ('rf', reg2), ('lr', reg3)])
    ereg.fit(X_train, y_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Train shape (110, 10)
    Test shape (10890, 10)

    VotingRegressor(estimators=[('gb', GradientBoostingRegressor(random_state=1)),
                                ('rf', RandomForestRegressor(random_state=1)),
                                ('lr', LinearRegression())])



.. GENERATED FROM PYTHON SOURCE LINES 51-60

Measure the processing time
+++++++++++++++++++++++++++

We use function :func:`skl2onnx.tutorial.measure_time`.
The page about `assume_finite <https://scikit-learn.org/
stable/modules/generated/sklearn.config_context.html>`_
may be useful if you need to optimize the prediction.
We measure the processing time per observation whether
or not an observation belongs to a batch or is a single one.

.. GENERATED FROM PYTHON SOURCE LINES 60-77

.. code-block:: default


    sizes = [(1, 50), (10, 50), (1000, 10), (10000, 5)]

    with config_context(assume_finite=True):
        obs = []
        for batch_size, repeat in tqdm(sizes):
            context = {"ereg": ereg, 'X': X_test[:batch_size]}
            mt = measure_time(
                "ereg.predict(X)", context, div_by_number=True,
                number=10, repeat=repeat)
            mt['size'] = context['X'].shape[0]
            mt['mean_obs'] = mt['average'] / mt['size']
            obs.append(mt)

    df_skl = DataFrame(obs)
    df_skl





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|                                                                                                                                                                        | 0/4 [00:00<?, ?it/s]     25%|########################################                                                                                                                        | 1/4 [00:04<00:12,  4.25s/it]     50%|################################################################################                                                                                | 2/4 [00:07<00:07,  3.56s/it]     75%|########################################################################################################################                                        | 3/4 [00:08<00:02,  2.60s/it]    100%|################################################################################################################################################################| 4/4 [00:13<00:00,  3.47s/it]    100%|################################################################################################################################################################| 4/4 [00:13<00:00,  3.40s/it]


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>average</th>
          <th>deviation</th>
          <th>min_exec</th>
          <th>max_exec</th>
          <th>repeat</th>
          <th>number</th>
          <th>size</th>
          <th>mean_obs</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.008484</td>
          <td>0.002852</td>
          <td>0.005614</td>
          <td>0.021584</td>
          <td>50</td>
          <td>10</td>
          <td>1</td>
          <td>0.008484</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.006129</td>
          <td>0.001059</td>
          <td>0.005506</td>
          <td>0.011207</td>
          <td>50</td>
          <td>10</td>
          <td>10</td>
          <td>0.000613</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.014580</td>
          <td>0.000389</td>
          <td>0.013978</td>
          <td>0.015171</td>
          <td>10</td>
          <td>10</td>
          <td>1000</td>
          <td>0.000015</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.096170</td>
          <td>0.003109</td>
          <td>0.093999</td>
          <td>0.102240</td>
          <td>5</td>
          <td>10</td>
          <td>10000</td>
          <td>0.000010</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 78-79

Graphe.

.. GENERATED FROM PYTHON SOURCE LINES 79-83

.. code-block:: default


    df_skl.set_index('size')[['mean_obs']].plot(
        title="scikit-learn", logx=True, logy=True)




.. image:: /auto_tutorial/images/sphx_glr_plot_bbegin_measure_time_001.png
    :alt: scikit-learn
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 84-89

ONNX runtime
++++++++++++

The same is done with the two ONNX runtime
available.

.. GENERATED FROM PYTHON SOURCE LINES 89-126

.. code-block:: default


    onx = to_onnx(ereg, X_train[:1].astype(numpy.float32))
    sess = InferenceSession(onx.SerializeToString())
    oinf = OnnxInference(onx, runtime="python_compiled")

    obs = []
    for batch_size, repeat in tqdm(sizes):

        # scikit-learn
        context = {"ereg": ereg, 'X': X_test[:batch_size].astype(numpy.float32)}
        mt = measure_time(
            "ereg.predict(X)", context, div_by_number=True,
            number=10, repeat=repeat)
        mt['size'] = context['X'].shape[0]
        mt['skl'] = mt['average'] / mt['size']

        # onnxruntime
        context = {"sess": sess, 'X': X_test[:batch_size].astype(numpy.float32)}
        mt2 = measure_time(
            "sess.run(None, {'X': X})[0]", context, div_by_number=True,
            number=10, repeat=repeat)
        mt['ort'] = mt2['average'] / mt['size']

        # mlprodict
        context = {"oinf": oinf, 'X': X_test[:batch_size].astype(numpy.float32)}
        mt2 = measure_time(
            "oinf.run({'X': X})['variable']", context, div_by_number=True,
            number=10, repeat=repeat)
        mt['pyrt'] = mt2['average'] / mt['size']

        # end
        obs.append(mt)


    df = DataFrame(obs)
    df





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|                                                                                                                                                                        | 0/4 [00:00<?, ?it/s]     25%|########################################                                                                                                                        | 1/4 [00:03<00:10,  3.51s/it]     50%|################################################################################                                                                                | 2/4 [00:07<00:07,  3.51s/it]     75%|########################################################################################################################                                        | 3/4 [00:09<00:03,  3.05s/it]    100%|################################################################################################################################################################| 4/4 [00:21<00:00,  6.38s/it]    100%|################################################################################################################################################################| 4/4 [00:21<00:00,  5.25s/it]


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>average</th>
          <th>deviation</th>
          <th>min_exec</th>
          <th>max_exec</th>
          <th>repeat</th>
          <th>number</th>
          <th>size</th>
          <th>skl</th>
          <th>ort</th>
          <th>pyrt</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.006122</td>
          <td>0.000503</td>
          <td>0.005596</td>
          <td>0.007436</td>
          <td>50</td>
          <td>10</td>
          <td>1</td>
          <td>0.006122</td>
          <td>0.000117</td>
          <td>0.000762</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.006322</td>
          <td>0.001172</td>
          <td>0.005584</td>
          <td>0.012818</td>
          <td>50</td>
          <td>10</td>
          <td>10</td>
          <td>0.000632</td>
          <td>0.000025</td>
          <td>0.000044</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.014403</td>
          <td>0.000310</td>
          <td>0.014056</td>
          <td>0.014960</td>
          <td>10</td>
          <td>10</td>
          <td>1000</td>
          <td>0.000014</td>
          <td>0.000004</td>
          <td>0.000007</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.101104</td>
          <td>0.005995</td>
          <td>0.095964</td>
          <td>0.111438</td>
          <td>5</td>
          <td>10</td>
          <td>10000</td>
          <td>0.000010</td>
          <td>0.000004</td>
          <td>0.000009</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 127-128

Graph.

.. GENERATED FROM PYTHON SOURCE LINES 128-133

.. code-block:: default


    df.set_index('size')[['skl', 'ort', 'pyrt']].plot(
        title="Average prediction time per runtime",
        logx=True, logy=True)




.. image:: /auto_tutorial/images/sphx_glr_plot_bbegin_measure_time_002.png
    :alt: Average prediction time per runtime
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 134-140

:epkg:`ONNX` runtimes are much faster than :epkg:`scikit-learn`
to predict one observation. :epkg:`scikit-learn` is optimized
for training, for batch prediction. That explains why
:epkg:`scikit-learn` and ONNX runtimes seem to converge
for big batches. They use similar implementation,
parallelization and languages (:epkg:`C++`, :epkg:`openmp`).


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  36.652 seconds)


.. _sphx_glr_download_auto_tutorial_plot_bbegin_measure_time.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/onnx/sklearn-onnx/master?filepath=notebooks/auto_tutorial/plot_bbegin_measure_time.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_bbegin_measure_time.py <plot_bbegin_measure_time.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_bbegin_measure_time.ipynb <plot_bbegin_measure_time.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
