
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorial/plot_ngrams.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_tutorial_plot_ngrams.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorial_plot_ngrams.py:


.. _example-ngrams:

Tricky issue when converting CountVectorizer or TfidfVectorizer
===============================================================

This issue is described at `scikit-learn/issues/13733
<https://github.com/scikit-learn/scikit-learn/issues/13733>`_.
If a CountVectorizer or a TfidfVectorizer produces a token with a space,
skl2onnx cannot know if it a bi-grams or a unigram with a space.

A simple example impossible to convert
++++++++++++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 17-41

.. code-block:: default


    import pprint
    import numpy
    from numpy.testing import assert_almost_equal
    from onnxruntime import InferenceSession
    from sklearn.feature_extraction.text import TfidfVectorizer
    from skl2onnx import to_onnx
    from skl2onnx.sklapi import TraceableTfidfVectorizer
    import skl2onnx.sklapi.register  # noqa

    corpus = numpy.array(
        [
            "This is the first document.",
            "This document is the second document.",
            "Is this the first document?",
            "",
        ]
    ).reshape((4,))

    pattern = r"\b[a-z ]{1,10}\b"
    mod1 = TfidfVectorizer(ngram_range=(1, 2), token_pattern=pattern)
    mod1.fit(corpus)







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>TfidfVectorizer(ngram_range=(1, 2), token_pattern=&#x27;\\b[a-z ]{1,10}\\b&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-12" type="checkbox" checked><label for="sk-estimator-id-12" class="sk-toggleable__label sk-toggleable__label-arrow">TfidfVectorizer</label><div class="sk-toggleable__content"><pre>TfidfVectorizer(ngram_range=(1, 2), token_pattern=&#x27;\\b[a-z ]{1,10}\\b&#x27;)</pre></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 42-44

Unigrams and bi-grams are placed into the following container
which maps it to its column index.

.. GENERATED FROM PYTHON SOURCE LINES 44-48

.. code-block:: default


    pprint.pprint(mod1.vocabulary_)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    {'document': 0,
     'document ': 1,
     'document  is the ': 2,
     'is the ': 3,
     'is the  second ': 4,
     'is this ': 5,
     'is this  the first ': 6,
     'second ': 7,
     'second  document': 8,
     'the first ': 9,
     'the first  document': 10,
     'this ': 11,
     'this  document ': 12,
     'this is ': 13,
     'this is  the first ': 14}




.. GENERATED FROM PYTHON SOURCE LINES 49-50

Conversion.

.. GENERATED FROM PYTHON SOURCE LINES 50-57

.. code-block:: default


    try:
        to_onnx(mod1, corpus)
    except RuntimeError as e:
        print(e)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    There were ambiguities between n-grams and tokens. 2 errors occurred. You can fix it by using class TraceableTfidfVectorizer.
    You can learn more at https://github.com/scikit-learn/scikit-learn/issues/13733.
    Unable to split n-grams 'is this  the first ' into tokens ('is', 'this', 'the', 'first ') existing in the vocabulary. Token 'is' does not exist in the vocabulary..
    Unable to split n-grams 'this is  the first ' into tokens ('this', 'is', 'the', 'first ') existing in the vocabulary. Token 'this' does not exist in the vocabulary..




.. GENERATED FROM PYTHON SOURCE LINES 58-65

TraceableTfidfVectorizer
++++++++++++++++++++++++

Class :class:`TraceableTfidfVectorizer` is equivalent to
:class:`sklearn.feature_extraction.text.TfidfVectorizer`
but stores the unigrams and bi-grams of the vocabulary with tuple
instead of concatenating every piece into a string.

.. GENERATED FROM PYTHON SOURCE LINES 65-72

.. code-block:: default



    mod2 = TraceableTfidfVectorizer(ngram_range=(1, 2), token_pattern=pattern)
    mod2.fit(corpus)

    pprint.pprint(mod2.vocabulary_)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    {('document',): 0,
     ('document ',): 1,
     ('document ', 'is the '): 2,
     ('is the ',): 3,
     ('is the ', 'second '): 4,
     ('is this ',): 5,
     ('is this ', 'the first '): 6,
     ('second ',): 7,
     ('second ', 'document'): 8,
     ('the first ',): 9,
     ('the first ', 'document'): 10,
     ('this ',): 11,
     ('this ', 'document '): 12,
     ('this is ',): 13,
     ('this is ', 'the first '): 14}




.. GENERATED FROM PYTHON SOURCE LINES 73-74

Let's check it produces the same results.

.. GENERATED FROM PYTHON SOURCE LINES 74-77

.. code-block:: default


    assert_almost_equal(mod1.transform(corpus).todense(), mod2.transform(corpus).todense())








.. GENERATED FROM PYTHON SOURCE LINES 78-82

Conversion. Line `import skl2onnx.sklapi.register`
was added to register the converters associated to these
new class. By default, only converters for scikit-learn are
declared.

.. GENERATED FROM PYTHON SOURCE LINES 82-87

.. code-block:: default


    onx = to_onnx(mod2, corpus)
    sess = InferenceSession(onx.SerializeToString(), providers=["CPUExecutionProvider"])
    got = sess.run(None, {"X": corpus})








.. GENERATED FROM PYTHON SOURCE LINES 88-89

Let's check if there are discrepancies...

.. GENERATED FROM PYTHON SOURCE LINES 89-91

.. code-block:: default


    assert_almost_equal(mod2.transform(corpus).todense(), got[0])








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.037 seconds)


.. _sphx_glr_download_auto_tutorial_plot_ngrams.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_ngrams.py <plot_ngrams.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_ngrams.ipynb <plot_ngrams.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
