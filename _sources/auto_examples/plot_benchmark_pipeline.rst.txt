
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_benchmark_pipeline.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_benchmark_pipeline.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_benchmark_pipeline.py:


Benchmark a pipeline
====================

The following example checks up on every step in a pipeline,
compares and benchmarks the predictions.

Create a pipeline
+++++++++++++++++

We reuse the pipeline implemented in example
`Pipelining: chaining a PCA and a logistic regression
<https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html>`_.
There is one change because
`ONNX-ML Imputer <https://github.com/onnx/onnx/blob/master/
docs/Operators-ml.md#ai.onnx.ml.Imputer>`_
does not handle string type. This cannot be part of the final ONNX pipeline
and must be removed. Look for comment starting with ``---`` below.

.. GENERATED FROM PYTHON SOURCE LINES 23-51

.. code-block:: default

    import skl2onnx
    import onnx
    import sklearn
    import numpy
    from skl2onnx.helpers import collect_intermediate_steps
    from timeit import timeit
    from skl2onnx.helpers import compare_objects
    import onnxruntime as rt
    from onnxconverter_common.data_types import FloatTensorType
    from skl2onnx import convert_sklearn
    import numpy as np
    import pandas as pd

    from sklearn import datasets
    from sklearn.decomposition import PCA
    from sklearn.linear_model import LogisticRegression
    from sklearn.pipeline import Pipeline

    logistic = LogisticRegression()
    pca = PCA()
    pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])

    digits = datasets.load_digits()
    X_digits = digits.data[:1000]
    y_digits = digits.target[:1000]

    pipe.fit(X_digits, y_digits)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/xadupre/github/scikit-learn/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA()), (&#x27;logistic&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" ><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA()), (&#x27;logistic&#x27;, LogisticRegression())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox" ><label for="sk-estimator-id-9" class="sk-toggleable__label sk-toggleable__label-arrow">PCA</label><div class="sk-toggleable__content"><pre>PCA()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox" ><label for="sk-estimator-id-10" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 52-54

Conversion to ONNX
++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 54-69

.. code-block:: default



    initial_types = [('input', FloatTensorType((None, X_digits.shape[1])))]
    model_onnx = convert_sklearn(pipe, initial_types=initial_types,
                                 target_opset=12)

    sess = rt.InferenceSession(model_onnx.SerializeToString(),
                               providers=["CPUExecutionProvider"])
    print("skl predict_proba")
    print(pipe.predict_proba(X_digits[:2]))
    onx_pred = sess.run(None, {'input': X_digits[:2].astype(np.float32)})[1]
    df = pd.DataFrame(onx_pred)
    print("onnx predict_proba")
    print(df.values)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    skl predict_proba
    [[9.99998536e-01 5.99063158e-19 3.48548953e-10 1.55765726e-08
      3.32559745e-10 1.21314653e-06 3.98959930e-08 1.22513839e-07
      2.23871272e-08 4.98148509e-08]
     [1.47648437e-14 9.99999301e-01 1.05811967e-10 7.49298733e-13
      2.48627417e-07 8.75686484e-12 5.39025135e-11 2.95899938e-11
      4.50528833e-07 1.30607478e-13]]
    onnx predict_proba
    [[9.99998569e-01 5.99062501e-19 3.48550355e-10 1.55766493e-08
      3.32561811e-10 1.21315134e-06 3.98961930e-08 1.22514706e-07
      2.23872494e-08 4.98151529e-08]
     [1.47648956e-14 9.99999285e-01 1.05811991e-10 7.49297488e-13
      2.48627885e-07 8.75685548e-12 5.39024415e-11 2.95899520e-11
      4.50529058e-07 1.30607344e-13]]




.. GENERATED FROM PYTHON SOURCE LINES 70-72

Comparing outputs
+++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 72-76

.. code-block:: default


    compare_objects(pipe.predict_proba(X_digits[:2]), onx_pred)
    # No exception so they are the same.








.. GENERATED FROM PYTHON SOURCE LINES 77-79

Benchmarks
++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 79-87

.. code-block:: default


    print("scikit-learn")
    print(timeit("pipe.predict_proba(X_digits[:1])",
                 number=10000, globals=globals()))
    print("onnxruntime")
    print(timeit("sess.run(None, {'input': X_digits[:1].astype(np.float32)})[1]",
                 number=10000, globals=globals()))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    scikit-learn
    2.355312850000246
    onnxruntime
    0.29348953099997743




.. GENERATED FROM PYTHON SOURCE LINES 88-96

Intermediate steps
++++++++++++++++++

Let's imagine the final output is wrong and we need
to look into each component of the pipeline which one
is failing. The following method modifies the scikit-learn
pipeline to steal the intermediate outputs and produces
an smaller ONNX graph for every operator.

.. GENERATED FROM PYTHON SOURCE LINES 96-127

.. code-block:: default



    steps = collect_intermediate_steps(
        pipe, "pipeline", initial_types)

    assert len(steps) == 2

    pipe.predict_proba(X_digits[:2])

    for i, step in enumerate(steps):
        onnx_step = step['onnx_step']
        sess = rt.InferenceSession(onnx_step.SerializeToString(),
                                   providers=["CPUExecutionProvider"])
        onnx_outputs = sess.run(None, {'input': X_digits[:2].astype(np.float32)})
        skl_outputs = step['model']._debug.outputs
        if 'transform' in skl_outputs:
            compare_objects(skl_outputs['transform'], onnx_outputs[0])
            print("benchmark", step['model'].__class__)
            print("scikit-learn")
            print(timeit("step['model'].transform(X_digits[:1])",
                         number=10000, globals=globals()))
        else:
            compare_objects(skl_outputs['predict_proba'], onnx_outputs[1])
            print("benchmark", step['model'].__class__)
            print("scikit-learn")
            print(timeit("step['model'].predict_proba(X_digits[:1])",
                         number=10000, globals=globals()))
        print("onnxruntime")
        print(timeit("sess.run(None, {'input': X_digits[:1].astype(np.float32)})",
                     number=10000, globals=globals()))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    benchmark <class 'sklearn.decomposition._pca.PCA'>
    scikit-learn
    0.6831115730001329
    onnxruntime
    0.16402971700017588
    benchmark <class 'sklearn.linear_model._logistic.LogisticRegression'>
    scikit-learn
    1.4586870539997108
    onnxruntime
    0.15432031699992876




.. GENERATED FROM PYTHON SOURCE LINES 128-129

**Versions used for this example**

.. GENERATED FROM PYTHON SOURCE LINES 129-135

.. code-block:: default


    print("numpy:", numpy.__version__)
    print("scikit-learn:", sklearn.__version__)
    print("onnx: ", onnx.__version__)
    print("onnxruntime: ", rt.__version__)
    print("skl2onnx: ", skl2onnx.__version__)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    numpy: 1.23.5
    scikit-learn: 1.3.dev0
    onnx:  1.14.0
    onnxruntime:  1.15.0+cpu
    skl2onnx:  1.14.0





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  6.685 seconds)


.. _sphx_glr_download_auto_examples_plot_benchmark_pipeline.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_benchmark_pipeline.py <plot_benchmark_pipeline.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_benchmark_pipeline.ipynb <plot_benchmark_pipeline.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
