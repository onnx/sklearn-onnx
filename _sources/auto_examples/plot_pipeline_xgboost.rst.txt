
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples\plot_pipeline_xgboost.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_pipeline_xgboost.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_pipeline_xgboost.py:


.. _example-xgboost:

Convert a pipeline with a XGBoost model
========================================

.. index:: XGBoost

*sklearn-onnx* only converts *scikit-learn* models into *ONNX*
but many libraries implement *scikit-learn* API so that their models
can be included in a *scikit-learn* pipeline. This example considers
a pipeline including a *XGBoost* model. *sklearn-onnx* can convert
the whole pipeline as long as it knows the converter associated to
a *XGBClassifier*. Let's see how to do it.

A couple of errors might happen while trying to convert
your own pipeline, some of them are described
and explained in :ref:`errors-pipeline`.

.. contents::
    :local:

Train a XGBoost classifier
++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 29-79

.. code-block:: default

    import os
    import numpy
    import matplotlib.pyplot as plt
    import onnx
    from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer
    import onnxruntime as rt
    import sklearn
    from sklearn.datasets import load_iris
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import StandardScaler
    import xgboost
    from xgboost import XGBClassifier
    import skl2onnx
    from skl2onnx.common.data_types import FloatTensorType
    from skl2onnx import convert_sklearn, update_registered_converter
    from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes  # noqa
    import onnxmltools
    from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost  # noqa
    import onnxmltools.convert.common.data_types

    data = load_iris()
    X = data.data[:, :2]
    y = data.target

    ind = numpy.arange(X.shape[0])
    numpy.random.shuffle(ind)
    X = X[ind, :].copy()
    y = y[ind].copy()

    pipe = Pipeline([('scaler', StandardScaler()),
                     ('lgbm', XGBClassifier(n_estimators=3))])
    pipe.fit(X, y)

    # The conversion fails but it is expected.

    try:
        convert_sklearn(pipe, 'pipeline_xgboost',
                        [('input', FloatTensorType([None, 2]))],
                        target_opset=12)
    except Exception as e:
        print(e)

    # The error message tells no converter was found
    # for XGBoost models. By default, *sklearn-onnx*
    # only handles models from *scikit-learn* but it can
    # be extended to every model following *scikit-learn*
    # API as long as the module knows there exists a converter
    # for every model used in a pipeline. That's why
    # we need to register a converter.





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    C:\Python395_x64\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
      warnings.warn(label_encoder_deprecation_msg, UserWarning)
    [15:59:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
    Unable to find a shape calculator for type '<class 'xgboost.sklearn.XGBClassifier'>'.
    It usually means the pipeline being converted contains a
    transformer or a predictor with no corresponding converter
    implemented in sklearn-onnx. If the converted is implemented
    in another library, you need to register
    the converted so that it can be used by sklearn-onnx (function
    update_registered_converter). If the model is not yet covered
    by sklearn-onnx, you may raise an issue to
    https://github.com/onnx/sklearn-onnx/issues
    to get the converter implemented or even contribute to the
    project. If the model is a custom model, a new converter must
    be implemented. Examples can be found in the gallery.





.. GENERATED FROM PYTHON SOURCE LINES 80-91

Register the converter for XGBClassifier
++++++++++++++++++++++++++++++++++++++++

The converter is implemented in *onnxmltools*:
`onnxmltools...XGBoost.py
<https://github.com/onnx/onnxmltools/blob/master/onnxmltools/convert/
xgboost/operator_converters/XGBoost.py>`_.
and the shape calculator:
`onnxmltools...Classifier.py
<https://github.com/onnx/onnxmltools/blob/master/onnxmltools/convert/
xgboost/shape_calculators/Classifier.py>`_.

.. GENERATED FROM PYTHON SOURCE LINES 93-94

Then we import the converter and shape calculator.

.. GENERATED FROM PYTHON SOURCE LINES 96-97

Let's register the new converter.

.. GENERATED FROM PYTHON SOURCE LINES 97-102

.. code-block:: default

    update_registered_converter(
        XGBClassifier, 'XGBoostXGBClassifier',
        calculate_linear_classifier_output_shapes, convert_xgboost,
        options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})








.. GENERATED FROM PYTHON SOURCE LINES 103-105

Convert again
+++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 105-115

.. code-block:: default


    model_onnx = convert_sklearn(
        pipe, 'pipeline_xgboost',
        [('input', FloatTensorType([None, 2]))],
        target_opset=12)

    # And save.
    with open("pipeline_xgboost.onnx", "wb") as f:
        f.write(model_onnx.SerializeToString())








.. GENERATED FROM PYTHON SOURCE LINES 116-120

Compare the predictions
+++++++++++++++++++++++

Predictions with XGBoost.

.. GENERATED FROM PYTHON SOURCE LINES 120-124

.. code-block:: default


    print("predict", pipe.predict(X[:5]))
    print("predict_proba", pipe.predict_proba(X[:1]))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    predict [1 0 1 2 1]
    predict_proba [[0.15194538 0.56404126 0.2840134 ]]




.. GENERATED FROM PYTHON SOURCE LINES 125-126

Predictions with onnxruntime.

.. GENERATED FROM PYTHON SOURCE LINES 126-132

.. code-block:: default


    sess = rt.InferenceSession("pipeline_xgboost.onnx")
    pred_onx = sess.run(None, {"input": X[:5].astype(numpy.float32)})
    print("predict", pred_onx[0])
    print("predict_proba", pred_onx[1][:1])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    predict [1 0 1 2 1]
    predict_proba [{0: 0.15194536745548248, 1: 0.564041256904602, 2: 0.2840133607387543}]




.. GENERATED FROM PYTHON SOURCE LINES 133-135

Display the ONNX graph
++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 135-150

.. code-block:: default


    pydot_graph = GetPydotGraph(
        model_onnx.graph, name=model_onnx.graph.name, rankdir="TB",
        node_producer=GetOpNodeProducer(
            "docstring", color="yellow",
            fillcolor="yellow", style="filled"))
    pydot_graph.write_dot("pipeline.dot")

    os.system('dot -O -Gdpi=300 -Tpng pipeline.dot')

    image = plt.imread("pipeline.dot.png")
    fig, ax = plt.subplots(figsize=(40, 20))
    ax.imshow(image)
    ax.axis('off')




.. image:: /auto_examples/images/sphx_glr_plot_pipeline_xgboost_001.png
    :alt: plot pipeline xgboost
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    (-0.5, 2112.5, 2558.5, -0.5)



.. GENERATED FROM PYTHON SOURCE LINES 151-152

**Versions used for this example**

.. GENERATED FROM PYTHON SOURCE LINES 152-160

.. code-block:: default


    print("numpy:", numpy.__version__)
    print("scikit-learn:", sklearn.__version__)
    print("onnx: ", onnx.__version__)
    print("onnxruntime: ", rt.__version__)
    print("skl2onnx: ", skl2onnx.__version__)
    print("onnxmltools: ", onnxmltools.__version__)
    print("xgboost: ", xgboost.__version__)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    numpy: 1.21.2
    scikit-learn: 1.1.dev0
    onnx:  1.10.1
    onnxruntime:  1.8.1
    skl2onnx:  1.9.3
    onnxmltools:  1.9.1
    xgboost:  1.4.2





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  3.444 seconds)


.. _sphx_glr_download_auto_examples_plot_pipeline_xgboost.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/onnx/onnx.ai/sklearn-onnx//master?filepath=auto_examples/auto_examples/plot_pipeline_xgboost.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_pipeline_xgboost.py <plot_pipeline_xgboost.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_pipeline_xgboost.ipynb <plot_pipeline_xgboost.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
