
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorial\plot_bbegin_measure_time.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_tutorial_plot_bbegin_measure_time.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorial_plot_bbegin_measure_time.py:


Benchmark ONNX conversion
=========================

.. index:: benchmark

Example :ref:`l-simple-deploy-1` converts a simple model.
This example takes a similar example but on random data
and compares the processing time required by each option
to compute predictions.

.. contents::
    :local:


Training a pipeline
+++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 21-50

.. code-block:: default

    import numpy
    from pandas import DataFrame
    from tqdm import tqdm
    from sklearn import config_context
    from sklearn.datasets import make_regression
    from sklearn.ensemble import (
        GradientBoostingRegressor, RandomForestRegressor,
        VotingRegressor)
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import train_test_split
    from mlprodict.onnxrt import OnnxInference
    from onnxruntime import InferenceSession
    from skl2onnx import to_onnx
    from skl2onnx.tutorial import measure_time


    N = 11000
    X, y = make_regression(N, n_features=10)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, train_size=0.01)
    print("Train shape", X_train.shape)
    print("Test shape", X_test.shape)

    reg1 = GradientBoostingRegressor(random_state=1)
    reg2 = RandomForestRegressor(random_state=1)
    reg3 = LinearRegression()
    ereg = VotingRegressor([('gb', reg1), ('rf', reg2), ('lr', reg3)])
    ereg.fit(X_train, y_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Train shape (110, 10)
    Test shape (10890, 10)

    VotingRegressor(estimators=[('gb', GradientBoostingRegressor(random_state=1)),
                                ('rf', RandomForestRegressor(random_state=1)),
                                ('lr', LinearRegression())])



.. GENERATED FROM PYTHON SOURCE LINES 51-60

Measure the processing time
+++++++++++++++++++++++++++

We use function :func:`skl2onnx.tutorial.measure_time`.
The page about `assume_finite <https://scikit-learn.org/
stable/modules/generated/sklearn.config_context.html>`_
may be useful if you need to optimize the prediction.
We measure the processing time per observation whether
or not an observation belongs to a batch or is a single one.

.. GENERATED FROM PYTHON SOURCE LINES 60-77

.. code-block:: default


    sizes = [(1, 50), (10, 50), (1000, 10), (10000, 5)]

    with config_context(assume_finite=True):
        obs = []
        for batch_size, repeat in tqdm(sizes):
            context = {"ereg": ereg, 'X': X_test[:batch_size]}
            mt = measure_time(
                "ereg.predict(X)", context, div_by_number=True,
                number=10, repeat=repeat)
            mt['size'] = context['X'].shape[0]
            mt['mean_obs'] = mt['average'] / mt['size']
            obs.append(mt)

    df_skl = DataFrame(obs)
    df_skl





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|                                                                                                                                                 | 0/4 [00:00<?, ?it/s]     25%|##################################2                                                                                                      | 1/4 [00:04<00:13,  4.50s/it]     50%|####################################################################5                                                                    | 2/4 [00:10<00:10,  5.23s/it]     75%|######################################################################################################7                                  | 3/4 [00:11<00:03,  3.63s/it]    100%|#########################################################################################################################################| 4/4 [00:17<00:00,  4.54s/it]    100%|#########################################################################################################################################| 4/4 [00:17<00:00,  4.48s/it]


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>average</th>
          <th>deviation</th>
          <th>min_exec</th>
          <th>max_exec</th>
          <th>repeat</th>
          <th>number</th>
          <th>size</th>
          <th>mean_obs</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.008995</td>
          <td>0.001882</td>
          <td>0.007290</td>
          <td>0.015356</td>
          <td>50</td>
          <td>10</td>
          <td>1</td>
          <td>0.008995</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.011461</td>
          <td>0.005183</td>
          <td>0.007003</td>
          <td>0.027637</td>
          <td>50</td>
          <td>10</td>
          <td>10</td>
          <td>0.001146</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.017187</td>
          <td>0.000584</td>
          <td>0.016396</td>
          <td>0.018379</td>
          <td>10</td>
          <td>10</td>
          <td>1000</td>
          <td>0.000017</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.118863</td>
          <td>0.011165</td>
          <td>0.109607</td>
          <td>0.140480</td>
          <td>5</td>
          <td>10</td>
          <td>10000</td>
          <td>0.000012</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 78-79

Graphe.

.. GENERATED FROM PYTHON SOURCE LINES 79-83

.. code-block:: default


    df_skl.set_index('size')[['mean_obs']].plot(
        title="scikit-learn", logx=True, logy=True)




.. image:: /auto_tutorial/images/sphx_glr_plot_bbegin_measure_time_001.png
    :alt: scikit-learn
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 84-89

ONNX runtime
++++++++++++

The same is done with the two ONNX runtime
available.

.. GENERATED FROM PYTHON SOURCE LINES 89-127

.. code-block:: default


    onx = to_onnx(ereg, X_train[:1].astype(numpy.float32),
                  target_opset=14)
    sess = InferenceSession(onx.SerializeToString())
    oinf = OnnxInference(onx, runtime="python_compiled")

    obs = []
    for batch_size, repeat in tqdm(sizes):

        # scikit-learn
        context = {"ereg": ereg, 'X': X_test[:batch_size].astype(numpy.float32)}
        mt = measure_time(
            "ereg.predict(X)", context, div_by_number=True,
            number=10, repeat=repeat)
        mt['size'] = context['X'].shape[0]
        mt['skl'] = mt['average'] / mt['size']

        # onnxruntime
        context = {"sess": sess, 'X': X_test[:batch_size].astype(numpy.float32)}
        mt2 = measure_time(
            "sess.run(None, {'X': X})[0]", context, div_by_number=True,
            number=10, repeat=repeat)
        mt['ort'] = mt2['average'] / mt['size']

        # mlprodict
        context = {"oinf": oinf, 'X': X_test[:batch_size].astype(numpy.float32)}
        mt2 = measure_time(
            "oinf.run({'X': X})['variable']", context, div_by_number=True,
            number=10, repeat=repeat)
        mt['pyrt'] = mt2['average'] / mt['size']

        # end
        obs.append(mt)


    df = DataFrame(obs)
    df





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|                                                                                                                                                 | 0/4 [00:00<?, ?it/s]     25%|##################################2                                                                                                      | 1/4 [00:03<00:10,  3.62s/it]     50%|####################################################################5                                                                    | 2/4 [00:07<00:07,  3.89s/it]     75%|######################################################################################################7                                  | 3/4 [00:10<00:03,  3.20s/it]    100%|#########################################################################################################################################| 4/4 [00:20<00:00,  6.11s/it]    100%|#########################################################################################################################################| 4/4 [00:20<00:00,  5.17s/it]


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>average</th>
          <th>deviation</th>
          <th>min_exec</th>
          <th>max_exec</th>
          <th>repeat</th>
          <th>number</th>
          <th>size</th>
          <th>skl</th>
          <th>ort</th>
          <th>pyrt</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.007067</td>
          <td>0.000580</td>
          <td>0.006427</td>
          <td>0.008704</td>
          <td>50</td>
          <td>10</td>
          <td>1</td>
          <td>0.007067</td>
          <td>0.000038</td>
          <td>0.000127</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.007848</td>
          <td>0.001922</td>
          <td>0.006455</td>
          <td>0.015135</td>
          <td>50</td>
          <td>10</td>
          <td>10</td>
          <td>0.000785</td>
          <td>0.000013</td>
          <td>0.000017</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.016560</td>
          <td>0.001642</td>
          <td>0.015117</td>
          <td>0.019907</td>
          <td>10</td>
          <td>10</td>
          <td>1000</td>
          <td>0.000017</td>
          <td>0.000002</td>
          <td>0.000005</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.127623</td>
          <td>0.013574</td>
          <td>0.113487</td>
          <td>0.150368</td>
          <td>5</td>
          <td>10</td>
          <td>10000</td>
          <td>0.000013</td>
          <td>0.000003</td>
          <td>0.000006</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 128-129

Graph.

.. GENERATED FROM PYTHON SOURCE LINES 129-134

.. code-block:: default


    df.set_index('size')[['skl', 'ort', 'pyrt']].plot(
        title="Average prediction time per runtime",
        logx=True, logy=True)




.. image:: /auto_tutorial/images/sphx_glr_plot_bbegin_measure_time_002.png
    :alt: Average prediction time per runtime
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 135-141

:epkg:`ONNX` runtimes are much faster than :epkg:`scikit-learn`
to predict one observation. :epkg:`scikit-learn` is optimized
for training, for batch prediction. That explains why
:epkg:`scikit-learn` and ONNX runtimes seem to converge
for big batches. They use similar implementation,
parallelization and languages (:epkg:`C++`, :epkg:`openmp`).


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  47.030 seconds)


.. _sphx_glr_download_auto_tutorial_plot_bbegin_measure_time.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/onnx/onnx.ai/sklearn-onnx//master?filepath=auto_examples/auto_tutorial/plot_bbegin_measure_time.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_bbegin_measure_time.py <plot_bbegin_measure_time.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_bbegin_measure_time.ipynb <plot_bbegin_measure_time.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
