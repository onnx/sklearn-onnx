
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorial/plot_dbegin_options_zipmap.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_tutorial_plot_dbegin_options_zipmap.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorial_plot_dbegin_options_zipmap.py:


.. _l-tutorial-example-zipmap:

Choose appropriate output of a classifier
=========================================

A scikit-learn classifier usually returns a matrix of probabilities.
By default, *sklearn-onnx* converts that matrix
into a list of dictionaries where each probabily is mapped
to its class id or name. That mechanism retains the class names
but is slower. Let's see what other options are available.

Train a model and convert it
++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 20-44

.. code-block:: default

    from timeit import repeat
    import numpy
    import sklearn
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    import onnxruntime as rt
    import onnx
    import skl2onnx
    from skl2onnx.common.data_types import FloatTensorType
    from skl2onnx import to_onnx
    from sklearn.linear_model import LogisticRegression
    from sklearn.multioutput import MultiOutputClassifier

    iris = load_iris()
    X, y = iris.data, iris.target
    X = X.astype(numpy.float32)
    y = y * 2 + 10  # to get labels different from [0, 1, 2]
    X_train, X_test, y_train, y_test = train_test_split(X, y)
    clr = LogisticRegression(max_iter=500)
    clr.fit(X_train, y_train)
    print(clr)

    onx = to_onnx(clr, X_train, target_opset=12)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    LogisticRegression(max_iter=500)




.. GENERATED FROM PYTHON SOURCE LINES 45-50

Default behaviour: zipmap=True
++++++++++++++++++++++++++++++

The output type for the probabilities is a list of
dictionaries.

.. GENERATED FROM PYTHON SOURCE LINES 50-57

.. code-block:: default


    sess = rt.InferenceSession(onx.SerializeToString(), providers=["CPUExecutionProvider"])
    res = sess.run(None, {"X": X_test})
    print(res[1][:2])
    print("probabilities type:", type(res[1]))
    print("type for the first observations:", type(res[1][0]))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [{10: 0.9532986879348755, 12: 0.046700991690158844, 14: 2.392355042957206e-07}, {10: 9.972082715137276e-09, 12: 0.0012002107687294483, 14: 0.9987998008728027}]
    probabilities type: <class 'list'>
    type for the first observations: <class 'dict'>




.. GENERATED FROM PYTHON SOURCE LINES 58-62

Option zipmap=False
+++++++++++++++++++

Probabilities are now a matrix.

.. GENERATED FROM PYTHON SOURCE LINES 62-75

.. code-block:: default


    initial_type = [("float_input", FloatTensorType([None, 4]))]
    options = {id(clr): {"zipmap": False}}
    onx2 = to_onnx(clr, X_train, options=options, target_opset=12)

    sess2 = rt.InferenceSession(
        onx2.SerializeToString(), providers=["CPUExecutionProvider"]
    )
    res2 = sess2.run(None, {"X": X_test})
    print(res2[1][:2])
    print("probabilities type:", type(res2[1]))
    print("type for the first observations:", type(res2[1][0]))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [[9.5329869e-01 4.6700992e-02 2.3923550e-07]
     [9.9720827e-09 1.2002108e-03 9.9879980e-01]]
    probabilities type: <class 'numpy.ndarray'>
    type for the first observations: <class 'numpy.ndarray'>




.. GENERATED FROM PYTHON SOURCE LINES 76-82

Option zipmap='columns'
+++++++++++++++++++++++

This options removes the final operator ZipMap and splits
the probabilities into columns. The final model produces
one output for the label, and one output per class.

.. GENERATED FROM PYTHON SOURCE LINES 82-98

.. code-block:: default


    options = {id(clr): {"zipmap": "columns"}}
    onx3 = to_onnx(clr, X_train, options=options, target_opset=12)

    sess3 = rt.InferenceSession(
        onx3.SerializeToString(), providers=["CPUExecutionProvider"]
    )
    res3 = sess3.run(None, {"X": X_test})
    for i, out in enumerate(sess3.get_outputs()):
        print(
            "output: '{}' shape={} values={}...".format(
                out.name, res3[i].shape, res3[i][:2]
            )
        )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    output: 'output_label' shape=(38,) values=[10 14]...
    output: 'i10' shape=(38,) values=[9.532987e-01 9.972083e-09]...
    output: 'i12' shape=(38,) values=[0.04670099 0.00120021]...
    output: 'i14' shape=(38,) values=[2.392355e-07 9.987998e-01]...




.. GENERATED FROM PYTHON SOURCE LINES 99-101

Let's compare prediction time
+++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 101-118

.. code-block:: default


    print("Average time with ZipMap:")
    print(sum(repeat(lambda: sess.run(None, {"X": X_test}), number=100, repeat=10)) / 10)

    print("Average time without ZipMap:")
    print(sum(repeat(lambda: sess2.run(None, {"X": X_test}), number=100, repeat=10)) / 10)

    print("Average time without ZipMap but with columns:")
    print(sum(repeat(lambda: sess3.run(None, {"X": X_test}), number=100, repeat=10)) / 10)

    # The prediction is much faster without ZipMap
    # on this example.
    # The optimisation is even faster when the classes
    # are described with strings and not integers
    # as the final result (list of dictionaries) may copy
    # many times the same information with onnxruntime.





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Average time with ZipMap:
    0.006968360000064422
    Average time without ZipMap:
    0.0026670199999898614
    Average time without ZipMap but with columns:
    0.004141249999884166




.. GENERATED FROM PYTHON SOURCE LINES 119-126

Option zimpap=False and output_class_labels=True
++++++++++++++++++++++++++++++++++++++++++++++++

Option `zipmap=False` seems a better choice because it is
much faster but labels are lost in the process. Option
`output_class_labels` can be used to expose the labels
as a third output.

.. GENERATED FROM PYTHON SOURCE LINES 126-139

.. code-block:: default


    initial_type = [("float_input", FloatTensorType([None, 4]))]
    options = {id(clr): {"zipmap": False, "output_class_labels": True}}
    onx4 = to_onnx(clr, X_train, options=options, target_opset=12)

    sess4 = rt.InferenceSession(
        onx4.SerializeToString(), providers=["CPUExecutionProvider"]
    )
    res4 = sess4.run(None, {"X": X_test})
    print(res4[1][:2])
    print("probabilities type:", type(res4[1]))
    print("class labels:", res4[2])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [[9.5329869e-01 4.6700992e-02 2.3923550e-07]
     [9.9720827e-09 1.2002108e-03 9.9879980e-01]]
    probabilities type: <class 'numpy.ndarray'>
    class labels: [10 12 14]




.. GENERATED FROM PYTHON SOURCE LINES 140-141

Processing time.

.. GENERATED FROM PYTHON SOURCE LINES 141-145

.. code-block:: default


    print("Average time without ZipMap but with output_class_labels:")
    print(sum(repeat(lambda: sess4.run(None, {"X": X_test}), number=100, repeat=10)) / 10)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Average time without ZipMap but with output_class_labels:
    0.003581729999950767




.. GENERATED FROM PYTHON SOURCE LINES 146-153

MultiOutputClassifier
+++++++++++++++++++++

This model is equivalent to several classifiers, one for every label
to predict. Instead of returning a matrix of probabilities, it returns
a sequence of matrices. Let's first modify the labels to get
a problem for a MultiOutputClassifier.

.. GENERATED FROM PYTHON SOURCE LINES 153-158

.. code-block:: default


    y = numpy.vstack([y, y + 100]).T
    y[::5, 1] = 1000  # Let's a fourth class.
    print(y[:5])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [[  10 1000]
     [  10  110]
     [  10  110]
     [  10  110]
     [  10  110]]




.. GENERATED FROM PYTHON SOURCE LINES 159-160

Let's train a MultiOutputClassifier.

.. GENERATED FROM PYTHON SOURCE LINES 160-174

.. code-block:: default


    X_train, X_test, y_train, y_test = train_test_split(X, y)
    clr = MultiOutputClassifier(LogisticRegression(max_iter=500))
    clr.fit(X_train, y_train)
    print(clr)

    onx5 = to_onnx(clr, X_train, target_opset=12)

    sess5 = rt.InferenceSession(
        onx5.SerializeToString(), providers=["CPUExecutionProvider"]
    )
    res5 = sess5.run(None, {"X": X_test[:3]})
    print(res5)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    MultiOutputClassifier(estimator=LogisticRegression(max_iter=500))
    /home/xadupre/github/sklearn-onnx/skl2onnx/_parse.py:551: UserWarning: Option zipmap is ignored for model <class 'sklearn.multioutput.MultiOutputClassifier'>. Set option zipmap to False to remove this message.
      warnings.warn(
    [array([[ 14, 114],
           [ 12, 112],
           [ 12, 112]], dtype=int64), [array([[1.5121835e-04, 1.6296931e-01, 8.3687949e-01],
           [7.3818588e-03, 7.9895413e-01, 1.9366404e-01],
           [4.2174147e-03, 8.5948825e-01, 1.3629435e-01]], dtype=float32), array([[4.0355229e-04, 1.9043219e-01, 5.6093395e-01, 2.4823032e-01],
           [5.2199918e-03, 4.4712257e-01, 1.9140574e-01, 3.5625172e-01],
           [3.1568978e-03, 5.7498026e-01, 1.5389088e-01, 2.6797205e-01]],
          dtype=float32)]]




.. GENERATED FROM PYTHON SOURCE LINES 175-177

Option zipmap is ignored. Labels are missing but they can be
added back as a third output.

.. GENERATED FROM PYTHON SOURCE LINES 177-194

.. code-block:: default


    onx6 = to_onnx(
        clr,
        X_train,
        target_opset=12,
        options={"zipmap": False, "output_class_labels": True},
    )

    sess6 = rt.InferenceSession(
        onx6.SerializeToString(), providers=["CPUExecutionProvider"]
    )
    res6 = sess6.run(None, {"X": X_test[:3]})
    print("predicted labels", res6[0])
    print("predicted probabilies", res6[1])
    print("class labels", res6[2])






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    predicted labels [[ 14 114]
     [ 12 112]
     [ 12 112]]
    predicted probabilies [array([[1.5121835e-04, 1.6296931e-01, 8.3687949e-01],
           [7.3818588e-03, 7.9895413e-01, 1.9366404e-01],
           [4.2174147e-03, 8.5948825e-01, 1.3629435e-01]], dtype=float32), array([[4.0355229e-04, 1.9043219e-01, 5.6093395e-01, 2.4823032e-01],
           [5.2199918e-03, 4.4712257e-01, 1.9140574e-01, 3.5625172e-01],
           [3.1568978e-03, 5.7498026e-01, 1.5389088e-01, 2.6797205e-01]],
          dtype=float32)]
    class labels [array([10, 12, 14], dtype=int64), array([ 110,  112,  114, 1000], dtype=int64)]




.. GENERATED FROM PYTHON SOURCE LINES 195-196

**Versions used for this example**

.. GENERATED FROM PYTHON SOURCE LINES 196-202

.. code-block:: default


    print("numpy:", numpy.__version__)
    print("scikit-learn:", sklearn.__version__)
    print("onnx: ", onnx.__version__)
    print("onnxruntime: ", rt.__version__)
    print("skl2onnx: ", skl2onnx.__version__)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    numpy: 1.23.5
    scikit-learn: 1.4.dev0
    onnx:  1.15.0
    onnxruntime:  1.16.0+cu118
    skl2onnx:  1.16.0





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.467 seconds)


.. _sphx_glr_download_auto_tutorial_plot_dbegin_options_zipmap.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_dbegin_options_zipmap.py <plot_dbegin_options_zipmap.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_dbegin_options_zipmap.ipynb <plot_dbegin_options_zipmap.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
