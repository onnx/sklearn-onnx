
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Issues when switching to float &#8212; sklearn-onnx 1.9.1.dev documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/readable.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Intermediate results and investigation" href="plot_fbegin_investigate.html" />
    <link rel="prev" title="Black list operators when converting" href="plot_dbegin_options_list.html" />
   
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">

  </head><body>
  
  

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="plot_fbegin_investigate.html" title="Intermediate results and investigation"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="plot_dbegin_options_list.html" title="Black list operators when converting"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">sklearn-onnx 1.9.1.dev documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index_tutorial.html" >Tutorial</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../tutorial_1_simple.html" accesskey="U">The easy case</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Issues when switching to float</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorial-plot-ebegin-float-double-py"><span class="std std-ref">here</span></a>
to download the full example code or to run this example in your browser via Binder</p>
</div>
<section class="sphx-glr-example-title" id="issues-when-switching-to-float">
<span id="l-example-discrepencies-float-double"></span><span id="sphx-glr-auto-tutorial-plot-ebegin-float-double-py"></span><h1>Issues when switching to float<a class="headerlink" href="#issues-when-switching-to-float" title="Permalink to this headline">¶</a></h1>
<p id="index-0">Most models in <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> do computation with double,
not float. Most models in deep learning use float because
that’s the most common situation with GPU. ONNX was initially
created to facilitate the deployment of deep learning models
and that explains why many converters assume the converted models
should use float. That assumption does not usually harm
the predictions, the conversion to float introduce small
discrepencies compare to double predictions.
That assumption is usually true if the prediction
function is continuous, <img class="math" src="../_images/math/5c81ce742afef9e6f20622db1228a9b431a1827a.png" alt="y = f(x)"/>, then
<img class="math" src="../_images/math/4d8ea6d344aebfca4fe35d95b736b0ac202d0df8.png" alt="dy = f'(x) dx"/>. We can determine an upper bound
to the discrepencies :
<img class="math" src="../_images/math/858e45c8f9ca8227d1cd82c88a0886ba1bb4ae8a.png" alt="\Delta(y) \leqslant \sup_x \left\Vert f'(x)\right\Vert dx"/>.
<em>dx</em> is the discrepency introduced by a float conversion,
<code class="docutils literal notranslate"><span class="pre">dx</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">-</span> <span class="pre">numpy.float32(x)</span></code>.</p>
<p>However, that’s not the case for every model. A decision tree
trained for a regression is not a continuous function. Therefore,
even a small <em>dx</em> may introduce a huge discrepency. Let’s look into
an example which always produces discrepencies and some ways
to overcome this situation.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#more-into-the-issue" id="id5">More into the issue</a></p></li>
<li><p><a class="reference internal" href="#the-pipeline-and-the-data" id="id6">The pipeline and the data</a></p></li>
<li><p><a class="reference internal" href="#the-discrepencies" id="id7">The discrepencies</a></p></li>
<li><p><a class="reference internal" href="#casttransformer" id="id8">CastTransformer</a></p></li>
<li><p><a class="reference internal" href="#sledgehammer" id="id9">Sledgehammer</a></p></li>
<li><p><a class="reference internal" href="#no-discrepencies-at-all" id="id10">No discrepencies at all?</a></p></li>
<li><p><a class="reference internal" href="#castregressor" id="id11">CastRegressor</a></p></li>
</ul>
</div>
<section id="more-into-the-issue">
<h2><a class="toc-backref" href="#id5">More into the issue</a><a class="headerlink" href="#more-into-the-issue" title="Permalink to this headline">¶</a></h2>
<p>The below example is built to fail.
It contains integer features with different order
of magnitude rounded to integer. A decision tree compares
features to thresholds. In most cases, float and double
comparison gives the same result. We denote
<img class="math" src="../_images/math/3b4d86b00d6c15831b3feb5246c37584439fdbdc.png" alt="[x]_{f32}"/> the conversion (or cast)
<code class="docutils literal notranslate"><span class="pre">numpy.float32(x)</span></code>.</p>
<div class="math">
<p><img src="../_images/math/c775a834bb5329566e258254aaedd2acbdc6a3b1.png" alt="x \leqslant y = [x]_{f32} \leqslant [y]_{f32}"/></p>
</div><p>However, the probability that both comparisons give
different results is not null. The following graph shows
the discord areas.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlprodict.sklapi</span> <span class="kn">import</span> <span class="n">OnnxPipeline</span>
<span class="kn">from</span> <span class="nn">skl2onnx.sklapi</span> <span class="kn">import</span> <span class="n">CastTransformer</span><span class="p">,</span> <span class="n">CastRegressor</span>
<span class="kn">from</span> <span class="nn">skl2onnx</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnx_conv</span> <span class="kn">import</span> <span class="n">to_onnx</span> <span class="k">as</span> <span class="n">to_onnx_extended</span>
<span class="kn">from</span> <span class="nn">mlprodict.onnxrt</span> <span class="kn">import</span> <span class="n">OnnxInference</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="k">def</span> <span class="nf">area_mismatch_rule</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">rule</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">rule</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">rule</span><span class="p">(</span><span class="n">t</span><span class="p">):</span> <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">xst</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">yst</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">xsf</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ysf</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
            <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
            <span class="n">dy</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">dx</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">dy</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">dx</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">rule</span><span class="p">(</span><span class="n">dy</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">key</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">c1</span> <span class="o">-</span> <span class="n">c2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">xsf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dx</span><span class="p">)</span>
                <span class="n">ysf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dy</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">xst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dx</span><span class="p">)</span>
                <span class="n">yst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dy</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xst</span><span class="p">,</span> <span class="n">yst</span><span class="p">,</span> <span class="n">xsf</span><span class="p">,</span> <span class="n">ysf</span>


<span class="n">delta</span> <span class="o">=</span> <span class="mf">36e-10</span>
<span class="n">factor</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">xst</span><span class="p">,</span> <span class="n">yst</span><span class="p">,</span> <span class="n">xsf</span><span class="p">,</span> <span class="n">ysf</span> <span class="o">=</span> <span class="n">area_mismatch_rule</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">factor</span><span class="p">)</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xst</span><span class="p">,</span> <span class="n">yst</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;agree&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xsf</span><span class="p">,</span> <span class="n">ysf</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;disagree&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Region where x &lt;= y and (float)x &lt;= (float)y agree&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">xst</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">xst</span><span class="p">)],</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">yst</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">yst</span><span class="p">)],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Region where x &lt;= y and (float)x &lt;= (float)y agree" class="sphx-glr-single-img" src="../_images/sphx_glr_plot_ebegin_float_double_001.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend object at 0x000001EE1621E040&gt;
</pre></div>
</div>
</section>
<section id="the-pipeline-and-the-data">
<h2><a class="toc-backref" href="#id6">The pipeline and the data</a><a class="headerlink" href="#the-pipeline-and-the-data" title="Permalink to this headline">¶</a></h2>
<p>We can now build an example where the learned decision tree
does many comparisons in this discord area. This is done
by rounding features to integers, a frequent case
happening when dealing with categorical features.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">Xi_test</span><span class="p">,</span> <span class="n">yi_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">Xi_train</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xi_train</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">Xi_test</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xi_test</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

<span class="n">max_depth</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;dt&#39;, DecisionTreeRegressor(max_depth=10))])
</pre></div>
</div>
</section>
<section id="the-discrepencies">
<h2><a class="toc-backref" href="#id7">The discrepencies</a><a class="headerlink" href="#the-discrepencies" title="Permalink to this headline">¶</a></h2>
<p>Let’s reuse the function implemented in the
first example <a class="reference internal" href="plot_abegin_convert_pipeline.html#l-diff-dicrepencies"><span class="std std-ref">Comparison</span></a> and
look into the conversion.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">diff</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">p2</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">p2</span> <span class="o">-</span> <span class="n">p1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="p">(</span><span class="n">d</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">p1</span><span class="p">))</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>


<span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="n">X32</span> <span class="o">=</span> <span class="n">Xi_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">skl</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl</span><span class="p">,</span> <span class="n">ort</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(363.4781090786519, 2.6694189950206964)
</pre></div>
</div>
<p>The discrepencies are significant.
The ONNX model keeps float at every step.</p>
<div><img height="120" src="../_images/blockdiag-93cbf409f95e8fcf3d4828de7d9adaafafd69550.png" width="1024" /></div><p>In <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>:</p>
<div><img height="120" src="../_images/blockdiag-5b571352ec916d18002a2d25df9e97f2ce3fe74d.png" width="1024" /></div></section>
<section id="casttransformer">
<h2><a class="toc-backref" href="#id8">CastTransformer</a><a class="headerlink" href="#casttransformer" title="Permalink to this headline">¶</a></h2>
<p>We could try to use double everywhere. Unfortunately,
<a href="#id1"><span class="problematic" id="id2">:epkg:`ONNX ML Operators`</span></a> only allows float coefficients
for the operator <em>TreeEnsembleRegressor</em>. We may want
to compromise by casting the output of the normalizer into
float in the <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> pipeline.</p>
<div><img height="120" src="../_images/blockdiag-e89f2384bd3fdbe24f74a006f4b52d484055dc82.png" width="1408" /></div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model2</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;cast&#39;</span><span class="p">,</span> <span class="n">CastTransformer</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()), (&#39;cast&#39;, CastTransformer()),
                (&#39;dt&#39;, DecisionTreeRegressor(max_depth=10))])
</pre></div>
</div>
<p>The discrepencies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx2</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model2</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sess2</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx2</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="n">skl2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort2</span> <span class="o">=</span> <span class="n">sess2</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl2</span><span class="p">,</span> <span class="n">ort2</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(363.4781090786519, 2.6694189950206964)
</pre></div>
</div>
<p>That still fails because the normalizer
in <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> and in <a class="reference external" href="https://onnx.ai/">ONNX</a>
use different types. The cast still happens and
the <em>dx</em> is still here. To remove it, we need to use
double in ONNX normalizer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model3</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;cast64&#39;</span><span class="p">,</span> <span class="n">CastTransformer</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;cast&#39;</span><span class="p">,</span> <span class="n">CastTransformer</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>
<span class="n">onx3</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model3</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
               <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="n">StandardScaler</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;div&#39;</span><span class="p">:</span> <span class="s1">&#39;div_cast&#39;</span><span class="p">}})</span>

<span class="n">sess3</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx3</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="n">skl3</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort3</span> <span class="o">=</span> <span class="n">sess3</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl3</span><span class="p">,</span> <span class="n">ort3</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(2.62539883806312e-05, 5.761867790906556e-08)
</pre></div>
</div>
<p>It works. That also means that it is difficult to change
the computation type when a pipeline includes a discontinuous
function. It is better to keep the same types all along
before using a decision tree.</p>
</section>
<section id="sledgehammer">
<h2><a class="toc-backref" href="#id9">Sledgehammer</a><a class="headerlink" href="#sledgehammer" title="Permalink to this headline">¶</a></h2>
<p>The idea here is to always train the next step based
on ONNX outputs. That way, every step of the pipeline
is trained based on ONNX output.</p>
<ul class="simple">
<li><p>Trains the first step.</p></li>
<li><p>Converts the step into ONNX</p></li>
<li><p>Computes ONNX outputs.</p></li>
<li><p>Trains the second step on these outputs.</p></li>
<li><p>Converts the second step into ONNX.</p></li>
<li><p>Merges it with the first step.</p></li>
<li><p>Computes ONNX outputs of the merged two first steps.</p></li>
<li><p>…</p></li>
</ul>
<p>It is implemented in
class <a class="reference external" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/mlprodict/sklapi/onnx_pipeline.html?highlight=onnxpipeline">OnnxPipeline</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_onx</span> <span class="o">=</span> <span class="n">OnnxPipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model_onx</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>OnnxPipeline(steps=[(&#39;scaler&#39;,
                     OnnxTransformer(onnx_bytes=b&#39;\x08\x06\x12\x08skl2onnx\x1a\t1.9.1.dev&quot;\x07ai.onnx(\x002\x00:\xf4\x01\n\xa6\x01\n\x01X\x12\x08variable\x1a\x06Scaler&quot;\x06Scaler*=\n\x06offset=+=\xc0\xba=RI\x1d\xbb=.\xda\xf6\xbc=\xdbC\xd5\xbd=\xe1U\xe9\xbe=M_b\xbe=a\x9e\xa8&gt;=\xb1\x9a\xa1\xbf=,@.?=\xc5 \x90\xc0\xa0\x01\x06*&lt;\n\x05scale=\xf8C...1a?=\x88k\x8f&gt;=\xa0Q\x07&gt;=\x11\xa1\x83==\x1a\xf1\x00==87\x7f&lt;=-\&#39;\x00&lt;=\xbc\x03\x80;=\xf7,\xff:\xa0\x01\x06:\nai.onnx.ml\x12\x1emlprodict_ONNX(StandardScaler)Z\x11\n\x01X\x12\x0c\n\n\x08\x01\x12\x06\n\x00\n\x02\x08\nb\x16\n\x08variable\x12\n\n\x08\x08\x01\x12\x04\n\x00\n\x00B\x0e\n\nai.onnx.ml\x10\x01&#39;)),
                    (&#39;dt&#39;, DecisionTreeRegressor(max_depth=10))])
</pre></div>
</div>
<p>The conversion.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">onx4</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model_onx</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sess4</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx4</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="n">skl4</span> <span class="o">=</span> <span class="n">model_onx</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort4</span> <span class="o">=</span> <span class="n">sess4</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl4</span><span class="p">,</span> <span class="n">ort4</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(2.8972554787287663e-05, 5.761867790906556e-08)
</pre></div>
</div>
<p>It works too in a more simple way.</p>
</section>
<section id="no-discrepencies-at-all">
<h2><a class="toc-backref" href="#id10">No discrepencies at all?</a><a class="headerlink" href="#no-discrepencies-at-all" title="Permalink to this headline">¶</a></h2>
<p>Is it possible to get no error at all?
There is one major obstacle: <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>
stores the predicted values in every leave with double
(<a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/tree/_tree.pyx#L1096">_tree.pyx - _get_value_ndarray</a>), <a class="reference external" href="https://onnx.ai/">ONNX</a> defines the
the predicted values as floats: <a href="#id3"><span class="problematic" id="id4">:epkg:`TreeEnsembleRegressor`</span></a>.
What can we do to solve it?
What if we could extend ONNX specifications to support
double instead of floats.
We reuse what was developped in example
<a class="reference external" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/notebooks/onnx_discrepencies.html?highlight=treeensembleregressordouble#other-way-to-convert">Other way to convert</a>
and a custom ONNX node <a class="reference external" href="http://www.xavierdupre.fr/app/mlprodict/helpsphinx/api/onnxrt_ops.html?highlight=treeensembleregressordouble#treeensembleregressordouble">TreeEnsembleRegressorDouble</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>

<span class="n">model_onx</span> <span class="o">=</span> <span class="n">to_onnx_extended</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
                             <span class="n">rewrite_ops</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">oinf5</span> <span class="o">=</span> <span class="n">OnnxInference</span><span class="p">(</span><span class="n">model_onx</span><span class="p">,</span> <span class="n">runtime</span><span class="o">=</span><span class="s1">&#39;python_compiled&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">oinf5</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>OnnxInference(...)
    def compiled_run(dict_inputs):
        # inputs
        X = dict_inputs[&#39;X&#39;]
        (variable, ) = n0_treeensembleregressordouble(X)
        return {
            &#39;variable&#39;: variable,
        }
</pre></div>
</div>
<p>Let’s measure the discrepencies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X64</span> <span class="o">=</span> <span class="n">Xi_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">skl5</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X64</span><span class="p">)</span>
<span class="n">ort5</span> <span class="o">=</span> <span class="n">oinf5</span><span class="o">.</span><span class="n">run</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X64</span><span class="p">})[</span><span class="s1">&#39;variable&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Perfect, no discrepencies at all.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl5</span><span class="p">,</span> <span class="n">ort5</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(0.0, 0.0)
</pre></div>
</div>
</section>
<section id="castregressor">
<h2><a class="toc-backref" href="#id11">CastRegressor</a><a class="headerlink" href="#castregressor" title="Permalink to this headline">¶</a></h2>
<p>The previous example demonstrated the type difference for
the predicted values explains the small differences between
<a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> and <a class="reference external" href="https://microsoft.github.io/onnxruntime/">onnxruntime</a>. But it does not
with the current ONNX. Another option is to cast the
the predictions into floats in the <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> pipeline.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ctree</span> <span class="o">=</span> <span class="n">CastRegressor</span><span class="p">(</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">))</span>
<span class="n">ctree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xi_train</span><span class="p">,</span> <span class="n">yi_train</span><span class="p">)</span>

<span class="n">onx6</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">ctree</span><span class="p">,</span> <span class="n">Xi_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sess6</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onx6</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

<span class="n">skl6</span> <span class="o">=</span> <span class="n">ctree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X32</span><span class="p">)</span>
<span class="n">ort6</span> <span class="o">=</span> <span class="n">sess6</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X32</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">(</span><span class="n">skl6</span><span class="p">,</span> <span class="n">ort6</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(0.0, 0.0)
</pre></div>
</div>
<p>Success!</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.996 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorial-plot-ebegin-float-double-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/onnx/sklearn-onnx/master?filepath=notebooks/auto_tutorial/plot_ebegin_float_double.ipynb"><img alt="Launch binder" src="../_images/binder_badge_logo1.svg" width="150px" /></a>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/3ea498c48f9870a80045a1cb2e840bbc/plot_ebegin_float_double.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_ebegin_float_double.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/b63a09caa8878af3c7bdcc0676f2c138/plot_ebegin_float_double.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_ebegin_float_double.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/logo_main.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Issues when switching to float</a><ul>
<li><a class="reference internal" href="#more-into-the-issue">More into the issue</a></li>
<li><a class="reference internal" href="#the-pipeline-and-the-data">The pipeline and the data</a></li>
<li><a class="reference internal" href="#the-discrepencies">The discrepencies</a></li>
<li><a class="reference internal" href="#casttransformer">CastTransformer</a></li>
<li><a class="reference internal" href="#sledgehammer">Sledgehammer</a></li>
<li><a class="reference internal" href="#no-discrepencies-at-all">No discrepencies at all?</a></li>
<li><a class="reference internal" href="#castregressor">CastRegressor</a></li>
</ul>
</li>
</ul>
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation index</a><ul>
  <li><a href="../index_tutorial.html">Tutorial</a><ul>
  <li><a href="../tutorial_1_simple.html">The easy case</a><ul>
      <li>Previous: <a href="plot_dbegin_options_list.html" title="previous chapter">Black list operators when converting</a></li>
      <li>Next: <a href="plot_fbegin_investigate.html" title="next chapter">Intermediate results and investigation</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/auto_tutorial/plot_ebegin_float_double.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
  <div class="footer">
    &copy; Copyright 2018-2021, Microsoft.
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.1.0.
  </div>
  
  </body>
</html>